{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Load all necessary packages\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from warnings import warn\n",
    "\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.datasets import StandardDataset\n",
    "from aif360.metrics import ClassificationMetric, BinaryLabelDatasetMetric\n",
    "from aif360.algorithms.postprocessing.reject_option_classification\\\n",
    "        import RejectOptionClassification\n",
    "from common_utils import compute_metrics\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interactive, FloatSlider\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huangrui's Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_continuous(df,collist,Nlevel):\n",
    "    for col in collist:\n",
    "        for q in range(1,Nlevel,1):\n",
    "            threshold = df[~np.isnan(df[col])][col].quantile(float(q)/Nlevel)\n",
    "            df[col+'_geq'+str(int(q))+'q'+str(threshold)] = (df[col] >= threshold).astype(float)\n",
    "    df.drop(collist,axis = 1, inplace = True)\n",
    "    \n",
    "class Zindi(StandardDataset):\n",
    "    \"\"\"financial-inclusion-in-africa dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path, label_name='Y', favorable_classes=[1],  \n",
    "                 protected_attribute_names=['sex'],\n",
    "                 privileged_classes=[[1]],\n",
    "                 instance_weights_name=None,\n",
    "                 categorical_features=[],\n",
    "                 features_to_drop=[],\n",
    "                 features_to_keep=[],\n",
    "                 na_values=[], custom_preprocessing=None,\n",
    "                 metadata=None):\n",
    "        \"\"\"See :obj:`RegressionDataset` for a description of the arguments.\"\"\"\n",
    "        \n",
    "\n",
    "        df = pd.read_csv(path)\n",
    "        numericals = [col for col in df.columns if len(df[col].unique())>2 and max(df[col])>1]\n",
    "        code_continuous(df,numericals, 5)\n",
    "\n",
    "        super(Zindi, self).__init__(\n",
    "            df=df, label_name=label_name,\n",
    "            favorable_classes=favorable_classes,\n",
    "            protected_attribute_names=protected_attribute_names,\n",
    "            privileged_classes=privileged_classes,\n",
    "            instance_weights_name=instance_weights_name,\n",
    "            categorical_features=categorical_features,\n",
    "            features_to_keep=features_to_keep,\n",
    "            features_to_drop=features_to_drop, na_values=na_values,\n",
    "            custom_preprocessing=custom_preprocessing, metadata=metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset and specify options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "\n",
    "# Metric used (should be one of allowed_metrics)\n",
    "metric_name = \"Equal opportunity difference\"\n",
    "        \n",
    "#random seed for calibrated equal odds prediction\n",
    "random_seed = 12345679\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# Verify metric name\n",
    "allowed_metrics = [\"Statistical parity difference\",\n",
    "                   \"Average odds difference\",\n",
    "                   \"Equal opportunity difference\"]\n",
    "if metric_name not in allowed_metrics:\n",
    "    raise ValueError(\"Metric name should be one of allowed metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into train, test and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for K in range(1, 6):\n",
    "    dataset_orig_train_valid= Zindi(path=\"./Huangrui/zindi/zindi_train{}.csv\".format(K))\n",
    "    dataset_orig_test= Zindi(path=\"./Huangrui/zindi/zindi_test{}.csv\".format(K))\n",
    "    # 80% train, 20% valid\n",
    "    dataset_orig_train, dataset_orig_valid = dataset_orig_train_valid.split([0.8], shuffle=True) \n",
    "        \n",
    "    # Lasso linear classifier and predictions\n",
    "    \n",
    "    lmod = pickle.load(open('experiments/zindi'+str(K)+'_sex_bmodel.pkl','rb'))[\"clf\"]\n",
    "\n",
    "    #training data\n",
    "    X_train = dataset_orig_train.features\n",
    "    y_train = dataset_orig_train.labels.ravel()\n",
    "    y_train_pred = lmod.predict(X_train)>0.5\n",
    "    #validation data\n",
    "    X_valid = dataset_orig_valid.features\n",
    "    y_valid = dataset_orig_valid.labels.ravel()\n",
    "    y_valid_pred = lmod.predict(X_valid)>0.5\n",
    "    #test data\n",
    "    dataset_orig_test_pred = dataset_orig_test.copy(deepcopy=True)\n",
    "    X_test = dataset_orig_test_pred.features\n",
    "    y_test = dataset_orig_test_pred.labels\n",
    "    y_test_pred = lmod.predict(X_test)>0.5\n",
    "\n",
    "    # save all the data\n",
    "    db = {}\n",
    "\n",
    "    db['Xtrain'] = X_train\n",
    "    db['Ytrain'] = y_train\n",
    "    db['Xval'] = X_valid\n",
    "    db['Yval'] = y_valid\n",
    "    db['Xtest'] = X_test\n",
    "    db['Ytest'] = y_test\n",
    "    db['clf'] = lmod\n",
    "    db['Ybtrain'] = y_train_pred\n",
    "    db['Ybval'] = y_valid_pred\n",
    "    db['Ybtest'] = y_test_pred\n",
    "    pickle.dump(db, open('experiments/zindi'+str(K)+'_sex.pkl','wb'))\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pickle.load(open('experiments/'+'zindi1_sex.pkl','rb')) \n",
    "Ytrain = db['Ytrain'] \n",
    "Yval = db['Yval']\n",
    "Ytest = db['Ytest'] \n",
    "clf = db['clf'] \n",
    "Ybtrain = db['Ybtrain'] # this is the predicted label of the biased decision-maker on training data\n",
    "Ybtest = db['Ybtest']\n",
    "Ybval = db['Ybval']\n",
    "Xtrain = db['Xtrain'] \n",
    "Xtest = db['Xtest'] \n",
    "Xval = db['Xval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11769394261424017"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(Ybval!=Yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 1., 0., 0.],\n",
       "       [1., 0., 0., ..., 1., 1., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 1., 1., 1.],\n",
       "       [1., 1., 0., ..., 1., 1., 1.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_orig_train.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.300e+01, 1.409e+03, 2.000e+00, ..., 0.000e+00, 1.000e+00,\n",
       "        0.000e+00],\n",
       "       [2.400e+01, 2.828e+03, 4.000e+00, ..., 1.000e+00, 1.000e+00,\n",
       "        0.000e+00],\n",
       "       [6.000e+00, 2.108e+03, 2.000e+00, ..., 0.000e+00, 1.000e+00,\n",
       "        0.000e+00],\n",
       "       ...,\n",
       "       [1.000e+01, 3.949e+03, 1.000e+00, ..., 0.000e+00, 1.000e+00,\n",
       "        0.000e+00],\n",
       "       [2.400e+01, 1.851e+03, 4.000e+00, ..., 1.000e+00, 1.000e+00,\n",
       "        0.000e+00],\n",
       "       [1.800e+01, 1.239e+03, 4.000e+00, ..., 0.000e+00, 1.000e+00,\n",
       "        0.000e+00]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
