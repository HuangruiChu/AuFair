{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "`load_boston` has been removed from scikit-learn since version 1.2.\n",
      "\n",
      "The Boston housing prices dataset has an ethical problem: as\n",
      "investigated in [1], the authors of this dataset engineered a\n",
      "non-invertible variable \"B\" assuming that racial self-segregation had a\n",
      "positive impact on house prices [2]. Furthermore the goal of the\n",
      "research that led to the creation of this dataset was to study the\n",
      "impact of air quality but it did not give adequate demonstration of the\n",
      "validity of this assumption.\n",
      "\n",
      "The scikit-learn maintainers therefore strongly discourage the use of\n",
      "this dataset unless the purpose of the code is to study and educate\n",
      "about ethical issues in data science and machine learning.\n",
      "\n",
      "In this special case, you can fetch the dataset from the original\n",
      "source::\n",
      "\n",
      "    import pandas as pd\n",
      "    import numpy as np\n",
      "\n",
      "    data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "    raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "    data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "    target = raw_df.values[1::2, 2]\n",
      "\n",
      "Alternative datasets include the California housing dataset and the\n",
      "Ames housing dataset. You can load the datasets as follows::\n",
      "\n",
      "    from sklearn.datasets import fetch_california_housing\n",
      "    housing = fetch_california_housing()\n",
      "\n",
      "for the California housing dataset and::\n",
      "\n",
      "    from sklearn.datasets import fetch_openml\n",
      "    housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "for the Ames housing dataset.\n",
      "\n",
      "[1] M Carlisle.\n",
      "\"Racist data destruction?\"\n",
      "<https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8>\n",
      "\n",
      "[2] Harrison Jr, David, and Daniel L. Rubinfeld.\n",
      "\"Hedonic housing prices and the demand for clean air.\"\n",
      "Journal of environmental economics and management 5.1 (1978): 81-102.\n",
      "<https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>\n",
      ": LawSchoolGPADataset will be unavailable. To install, run:\n",
      "pip install 'aif360[LawSchoolGPA]'\n",
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# Load all necessary packages\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from warnings import warn\n",
    "\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.datasets import StandardDataset\n",
    "from aif360.metrics import ClassificationMetric, BinaryLabelDatasetMetric\n",
    "from aif360.algorithms.postprocessing.reject_option_classification\\\n",
    "        import RejectOptionClassification\n",
    "from common_utils import compute_metrics\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interactive, FloatSlider\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huangrui's Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_preproc_data_german(protected_attributes=None):\n",
    "#     \"\"\"\n",
    "#     Load and pre-process german credit dataset.\n",
    "#     Args:\n",
    "#         protected_attributes(list or None): If None use all possible protected\n",
    "#             attributes, else subset the protected attributes to the list.\n",
    "\n",
    "#     Returns:\n",
    "#         GermanDataset: An instance of GermanDataset with required pre-processing.\n",
    "\n",
    "#     \"\"\"\n",
    "#     def custom_preprocessing(df):\n",
    "#         \"\"\" Custom pre-processing for German Credit Data\n",
    "#         \"\"\"\n",
    "\n",
    "#         def group_credit_hist(x):\n",
    "#             if x in ['A30', 'A31', 'A32']:\n",
    "#                 return 'None/Paid'\n",
    "#             elif x == 'A33':\n",
    "#                 return 'Delay'\n",
    "#             elif x == 'A34':\n",
    "#                 return 'Other'\n",
    "#             else:\n",
    "#                 return 'NA'\n",
    "\n",
    "#         def group_employ(x):\n",
    "#             if x == 'A71':\n",
    "#                 return 'Unemployed'\n",
    "#             elif x in ['A72', 'A73']:\n",
    "#                 return '1-4 years'\n",
    "#             elif x in ['A74', 'A75']:\n",
    "#                 return '4+ years'\n",
    "#             else:\n",
    "#                 return 'NA'\n",
    "\n",
    "#         def group_savings(x):\n",
    "#             if x in ['A61', 'A62']:\n",
    "#                 return '<500'\n",
    "#             elif x in ['A63', 'A64']:\n",
    "#                 return '500+'\n",
    "#             elif x == 'A65':\n",
    "#                 return 'Unknown/None'\n",
    "#             else:\n",
    "#                 return 'NA'\n",
    "\n",
    "#         def group_status(x):\n",
    "#             if x in ['A22', 'A22']:\n",
    "#                 return '<200'\n",
    "#             elif x in ['A23']:\n",
    "#                 return '200+'\n",
    "#             elif x == 'A14':\n",
    "#                 return 'None'\n",
    "#             else:\n",
    "#                 return 'NA'\n",
    "\n",
    "#         status_map = {'A91': 1.0, 'A93': 1.0, 'A94': 1.0,\n",
    "#                     'A92': 0.0, 'A95': 0.0}\n",
    "#         df['sex'] = df['personal_status'].replace(status_map)\n",
    "#         #drop personal_status,not leak sex information\n",
    "#         df = df.drop('personal_status', axis=1)\n",
    "\n",
    "#         # group credit history, savings, and employment\n",
    "#         df['credit_history'] = df['credit_history'].apply(lambda x: group_credit_hist(x))\n",
    "#         df['savings'] = df['savings'].apply(lambda x: group_savings(x))\n",
    "#         df['employment'] = df['employment'].apply(lambda x: group_employ(x))\n",
    "#         df['age'] = (df['age'] >= 26).astype(float)\n",
    "#         df['status'] = df['status'].apply(lambda x: group_status(x))\n",
    "#         df[\"Y\"] = df[\"credit\"].apply(lambda x: 1 if x == 1 else 0)\n",
    "#         df.drop([\"credit\"], axis=1, inplace=True)\n",
    "#         return df\n",
    "\n",
    "#     # Feature partitions\n",
    "#     D_features = ['sex', 'age'] if protected_attributes is None else protected_attributes\n",
    "#     Y_features = ['Y']\n",
    "\n",
    "#     # privileged classes\n",
    "#     all_privileged_classes = {\"sex\": [1.0],\n",
    "#                               \"age\": [1.0]}\n",
    "\n",
    "#     # protected attribute maps\n",
    "#     all_protected_attribute_maps = {\"sex\": {1.0: 'Male', 0.0: 'Female'},\n",
    "#                                     \"age\": {1.0: 'Old', 0.0: 'Young'}}\n",
    "\n",
    "#     return GermanDataset(\n",
    "#         label_name=Y_features[0],\n",
    "#         favorable_classes=[1],\n",
    "#         protected_attribute_names=D_features,\n",
    "#         privileged_classes=[all_privileged_classes[x] for x in D_features],\n",
    "#         instance_weights_name=None,\n",
    "#         features_to_keep=[],\n",
    "#         metadata={ 'label_maps': [{1.0: 'Good Credit', 0: 'Bad Credit'}],\n",
    "#                    'protected_attribute_maps': [all_protected_attribute_maps[x]\n",
    "#                                 for x in D_features]},\n",
    "#         custom_preprocessing=custom_preprocessing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GermanDataset(StandardDataset):\n",
    "    \"\"\"German credit Dataset.\n",
    "\n",
    "    See :file:`aif360/data/raw/german/README.md`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path, label_name='Y', favorable_classes=[1],\n",
    "                 protected_attribute_names=['sex', 'age'],\n",
    "                 privileged_classes=[[1],[1]],\n",
    "                 instance_weights_name=None,\n",
    "                 categorical_features=[],\n",
    "                 features_to_keep=[], features_to_drop=[],\n",
    "                 na_values=[], custom_preprocessing=None,\n",
    "                 metadata=None):\n",
    "        \n",
    "        df = pd.read_csv(path)\n",
    "        \n",
    "\n",
    "        super(GermanDataset, self).__init__(df=df, label_name=label_name,\n",
    "            favorable_classes=favorable_classes,\n",
    "            protected_attribute_names=protected_attribute_names,\n",
    "            privileged_classes=privileged_classes,\n",
    "            instance_weights_name=instance_weights_name,\n",
    "            categorical_features=categorical_features,\n",
    "            features_to_keep=features_to_keep,\n",
    "            features_to_drop=features_to_drop, na_values=na_values,\n",
    "            custom_preprocessing=custom_preprocessing, metadata=metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset and specify options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import dataset\n",
    "dataset_used = \"german\" # \"german\", \"german\", \"compas\"\n",
    "protected_attribute_used = 2 # 1, 2\n",
    "\n",
    "\n",
    "#     dataset_orig = GermanDataset()\n",
    "if protected_attribute_used == 1:\n",
    "    privileged_groups = [{'sex': 1}]\n",
    "    unprivileged_groups = [{'sex': 0}]\n",
    "else:\n",
    "    privileged_groups = [{'age': 1}]\n",
    "    unprivileged_groups = [{'age': 0}]\n",
    "        \n",
    "# Metric used (should be one of allowed_metrics)\n",
    "metric_name = \"Equal opportunity difference\"\n",
    "\n",
    "# Upper and lower bound on the fairness metric used\n",
    "metric_ub = 0.05\n",
    "metric_lb = -0.05\n",
    "        \n",
    "        \n",
    "#random seed for calibrated equal odds prediction\n",
    "random_seed = 12345679\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# Verify metric name\n",
    "allowed_metrics = [\"Statistical parity difference\",\n",
    "                   \"Average odds difference\",\n",
    "                   \"Equal opportunity difference\"]\n",
    "if metric_name not in allowed_metrics:\n",
    "    raise ValueError(\"Metric name should be one of allowed metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into train, test and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 5 fold cross validation\n",
    "# Z =  dataset_orig.split(5, shuffle=True,seed = random_seed)\n",
    "# # i th fold\n",
    "# dataset_train1 = Z[0].copy()\n",
    "# dataset_train1.features = np.concatenate((Z[0].features,Z[1].features,Z[2].features,Z[3].features),axis=0)\n",
    "# dataset_train1.scores = np.concatenate((Z[0].scores,Z[1].scores,Z[2].scores,Z[3].scores),axis=0)\n",
    "# dataset_train1.labels = np.concatenate((Z[0].labels,Z[1].labels,Z[2].labels,Z[3].labels),axis=0)\n",
    "# dataset_train1.protected_attributes = np.concatenate((Z[0].protected_attributes,Z[1].protected_attributes,Z[2].protected_attributes,Z[3].protected_attributes),axis=0)\n",
    "# dataset_train1.instance_weights = np.concatenate((Z[0].instance_weights,Z[1].instance_weights,Z[2].instance_weights,Z[3].instance_weights),axis=0)\n",
    "# dataset_train1.instance_names = np.concatenate((Z[0].instance_names,Z[1].instance_names,Z[2].instance_names,Z[3].instance_names),axis=0)\n",
    "# dataset_train1.metadata = Z[0].metadata.copy()\n",
    "# dataset_test1= Z[4].copy()\n",
    "\n",
    "# dataset_train2 = Z[1].copy()\n",
    "# dataset_train2.features = np.concatenate((Z[1].features,Z[2].features,Z[3].features,Z[4].features),axis=0)\n",
    "# dataset_train2.scores = np.concatenate((Z[1].scores,Z[2].scores,Z[3].scores,Z[4].scores),axis=0)\n",
    "# dataset_train2.labels = np.concatenate((Z[1].labels,Z[2].labels,Z[3].labels,Z[4].labels),axis=0)\n",
    "# dataset_train2.protected_attributes = np.concatenate((Z[1].protected_attributes,Z[2].protected_attributes,Z[3].protected_attributes,Z[4].protected_attributes),axis=0)\n",
    "# dataset_train2.instance_weights = np.concatenate((Z[1].instance_weights,Z[2].instance_weights,Z[3].instance_weights,Z[4].instance_weights),axis=0)\n",
    "# dataset_train2.instance_names = np.concatenate((Z[1].instance_names,Z[2].instance_names,Z[3].instance_names,Z[4].instance_names),axis=0)\n",
    "# dataset_train2.metadata = Z[1].metadata.copy()\n",
    "# dataset_test2= Z[0].copy()\n",
    "\n",
    "# dataset_train3 = Z[2].copy()\n",
    "# dataset_train3.features = np.concatenate((Z[2].features,Z[3].features,Z[4].features,Z[0].features),axis=0)\n",
    "# dataset_train3.scores = np.concatenate((Z[2].scores,Z[3].scores,Z[4].scores,Z[0].scores),axis=0)\n",
    "# dataset_train3.labels = np.concatenate((Z[2].labels,Z[3].labels,Z[4].labels,Z[0].labels),axis=0)\n",
    "# dataset_train3.protected_attributes = np.concatenate((Z[2].protected_attributes,Z[3].protected_attributes,Z[4].protected_attributes,Z[0].protected_attributes),axis=0)\n",
    "# dataset_train3.instance_weights = np.concatenate((Z[2].instance_weights,Z[3].instance_weights,Z[4].instance_weights,Z[0].instance_weights),axis=0)\n",
    "# dataset_train3.instance_names = np.concatenate((Z[2].instance_names,Z[3].instance_names,Z[4].instance_names,Z[0].instance_names),axis=0)\n",
    "# dataset_train3.metadata = Z[2].metadata.copy()\n",
    "# dataset_test3= Z[1].copy()\n",
    "\n",
    "# dataset_train4 = Z[3].copy()\n",
    "# dataset_train4.features = np.concatenate((Z[3].features,Z[4].features,Z[0].features,Z[1].features),axis=0)\n",
    "# dataset_train4.scores = np.concatenate((Z[3].scores,Z[4].scores,Z[0].scores,Z[1].scores),axis=0)\n",
    "# dataset_train4.labels = np.concatenate((Z[3].labels,Z[4].labels,Z[0].labels,Z[1].labels),axis=0)\n",
    "# dataset_train4.protected_attributes = np.concatenate((Z[3].protected_attributes,Z[4].protected_attributes,Z[0].protected_attributes,Z[1].protected_attributes),axis=0)\n",
    "# dataset_train4.instance_weights = np.concatenate((Z[3].instance_weights,Z[4].instance_weights,Z[0].instance_weights,Z[1].instance_weights),axis=0)\n",
    "# dataset_train4.instance_names = np.concatenate((Z[3].instance_names,Z[4].instance_names,Z[0].instance_names,Z[1].instance_names),axis=0)\n",
    "# dataset_train4.metadata = Z[3].metadata.copy()\n",
    "# dataset_test4= Z[2].copy()\n",
    "\n",
    "# dataset_train5 = Z[4].copy()\n",
    "# dataset_train5.features = np.concatenate((Z[4].features,Z[0].features,Z[1].features,Z[2].features),axis=0)\n",
    "# dataset_train5.scores = np.concatenate((Z[4].scores,Z[0].scores,Z[1].scores,Z[2].scores),axis=0)\n",
    "# dataset_train5.labels = np.concatenate((Z[4].labels,Z[0].labels,Z[1].labels,Z[2].labels),axis=0)\n",
    "# dataset_train5.protected_attributes = np.concatenate((Z[4].protected_attributes,Z[0].protected_attributes,Z[1].protected_attributes,Z[2].protected_attributes),axis=0)\n",
    "# dataset_train5.instance_weights = np.concatenate((Z[4].instance_weights,Z[0].instance_weights,Z[1].instance_weights,Z[2].instance_weights),axis=0)\n",
    "# dataset_train5.instance_names = np.concatenate((Z[4].instance_names,Z[0].instance_names,Z[1].instance_names,Z[2].instance_names),axis=0)\n",
    "# dataset_train5.metadata = Z[4].metadata.copy()\n",
    "# dataset_test5= Z[3].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_train1.convert_to_dataframe()[0].to_csv(\"Huangrui/german/german_train1.csv\",index=False)\n",
    "# dataset_test1.convert_to_dataframe()[0].to_csv(\"Huangrui/german/german_test1.csv\",index=False)\n",
    "# dataset_train2.convert_to_dataframe()[0].to_csv(\"Huangrui/german/german_train2.csv\",index=False)\n",
    "# dataset_test2.convert_to_dataframe()[0].to_csv(\"Huangrui/german/german_test2.csv\",index=False)\n",
    "# dataset_train3.convert_to_dataframe()[0].to_csv(\"Huangrui/german/german_train3.csv\",index=False)\n",
    "# dataset_test3.convert_to_dataframe()[0].to_csv(\"Huangrui/german/german_test3.csv\",index=False)\n",
    "# dataset_train4.convert_to_dataframe()[0].to_csv(\"Huangrui/german/german_train4.csv\",index=False)\n",
    "# dataset_test4.convert_to_dataframe()[0].to_csv(\"Huangrui/german/german_test4.csv\",index=False)\n",
    "# dataset_train5.convert_to_dataframe()[0].to_csv(\"Huangrui/german/german_train5.csv\",index=False)\n",
    "# dataset_test5.convert_to_dataframe()[0].to_csv(\"Huangrui/german/german_test5.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n",
      "0.27\n",
      "Balanced accuracy = 0.6342\n",
      "Statistical parity difference = -0.2615\n",
      "Disparate impact = 0.6799\n",
      "Average odds difference = -0.2543\n",
      "Equal opportunity difference = -0.2443\n",
      "Theil index = 0.1674\n",
      "Balanced accuracy = 0.7538\n",
      "Statistical parity difference = -0.3858\n",
      "Disparate impact = 0.5118\n",
      "Average odds difference = -0.2772\n",
      "Equal opportunity difference = -0.2794\n",
      "Theil index = 0.1237\n"
     ]
    }
   ],
   "source": [
    "protected_attribute_used = 2\n",
    "K = 2\n",
    "#     dataset_orig = GermanDataset()\n",
    "if protected_attribute_used == 1:\n",
    "    privileged_groups = [{'sex': 1}]\n",
    "    unprivileged_groups = [{'sex': 0}]\n",
    "else:\n",
    "    privileged_groups = [{'age': 1}]\n",
    "    unprivileged_groups = [{'age': 0}]\n",
    "\n",
    "if protected_attribute_used == 1:\n",
    "    dataset_orig_train= GermanDataset(path=\"./Huangrui/german/german_train{}.csv\".format(K),protected_attribute_names=['sex'],\n",
    "                 privileged_classes=[[1]])\n",
    "    dataset_orig_test= GermanDataset(path=\"./Huangrui/german/german_test{}.csv\".format(K),protected_attribute_names=['sex'],\n",
    "                 privileged_classes=[[1]])\n",
    "else:\n",
    "    dataset_orig_train= GermanDataset(path=\"./Huangrui/german/german_train{}.csv\".format(K),protected_attribute_names=['age'],\n",
    "                 privileged_classes=[[1]])\n",
    "    dataset_orig_test= GermanDataset(path=\"./Huangrui/german/german_test{}.csv\".format(K),protected_attribute_names=['age'],\n",
    "                 privileged_classes=[[1]])\n",
    "import pickle\n",
    "from sklearn.linear_model import Lasso\n",
    "# 用部分 data训练 biased model\n",
    "selected_dataset,_ = dataset_orig_train.split([0.6], shuffle=True)\n",
    "_ =  dataset_orig_test\n",
    "# Logistic regression classifier and predictions\n",
    "scale_orig = StandardScaler()\n",
    "X_train = scale_orig.fit_transform(selected_dataset.features)\n",
    "y_train = selected_dataset.labels.ravel()\n",
    "X_test = scale_orig.fit_transform(_.features)\n",
    "y_test = _.labels.ravel()\n",
    "lmod = Lasso(alpha = 0.001)\n",
    "lmod.fit(X_train, y_train)\n",
    "y_train_pred = lmod.predict(X_train)>0.5\n",
    "y_test_pred = lmod.predict(X_test)>0.5\n",
    "dataset_orig_train_pred = selected_dataset.copy(deepcopy=True)\n",
    "dataset_orig_train_pred.labels = y_train_pred\n",
    "dataset_orig_test_pred = _.copy(deepcopy=True)\n",
    "dataset_orig_test_pred.labels = y_test_pred\n",
    "print(np.mean(y_train_pred!=y_train))\n",
    "print(np.mean(y_test_pred!=y_test))\n",
    "metric_test = compute_metrics(_, dataset_orig_test_pred, \n",
    "                unprivileged_groups, privileged_groups)\n",
    "metric_train = compute_metrics(selected_dataset, dataset_orig_train_pred,unprivileged_groups, privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Training Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 51)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Favorable and unfavorable labels"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Protected attribute names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Privileged and unprivileged protected attribute values"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.])] [array([0.])]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Dataset feature names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['month', 'credit_amount', 'investment_as_income_percentage', 'residence_since', 'age', 'number_of_credits', 'people_liable_for', 'sex', 'status=200+', 'status=<200', 'status=None', 'credit_history=Delay', 'credit_history=None/Paid', 'credit_history=Other', 'purpose=A40', 'purpose=A41', 'purpose=A410', 'purpose=A42', 'purpose=A43', 'purpose=A44', 'purpose=A45', 'purpose=A46', 'purpose=A48', 'purpose=A49', 'savings=500+', 'savings=<500', 'savings=Unknown/None', 'employment=1-4 years', 'employment=4+ years', 'employment=Unemployed', 'other_debtors=A101', 'other_debtors=A102', 'other_debtors=A103', 'property=A121', 'property=A122', 'property=A123', 'property=A124', 'installment_plans=A141', 'installment_plans=A142', 'installment_plans=A143', 'housing=A151', 'housing=A152', 'housing=A153', 'skill_level=A171', 'skill_level=A172', 'skill_level=A173', 'skill_level=A174', 'telephone=A191', 'telephone=A192', 'foreign_worker=A201', 'foreign_worker=A202']\n"
     ]
    }
   ],
   "source": [
    "# print out some labels, names, etc.\n",
    "display(Markdown(\"#### Training Dataset shape\"))\n",
    "print(dataset_orig_train.features.shape)\n",
    "display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
    "print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
    "display(Markdown(\"#### Protected attribute names\"))\n",
    "print(dataset_orig_train.protected_attribute_names)\n",
    "display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
    "print(dataset_orig_train.privileged_protected_attributes, \n",
    "      dataset_orig_train.unprivileged_protected_attributes)\n",
    "display(Markdown(\"#### Dataset feature names\"))\n",
    "print(dataset_orig_train.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "bmodels = {}\n",
    "bmodels['clf'] = lmod\n",
    "pickle.dump(bmodels, open(\"experiments/german\"+str(K)+'_age_bmodel.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
