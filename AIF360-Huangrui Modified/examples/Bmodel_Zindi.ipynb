{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Load all necessary packages\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from warnings import warn\n",
    "\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.datasets import StandardDataset\n",
    "from aif360.metrics import ClassificationMetric, BinaryLabelDatasetMetric\n",
    "from aif360.algorithms.postprocessing.reject_option_classification\\\n",
    "        import RejectOptionClassification\n",
    "from common_utils import compute_metrics\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interactive, FloatSlider\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huangrui's Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_continuous(df,collist,Nlevel):\n",
    "    for col in collist:\n",
    "        for q in range(1,Nlevel,1):\n",
    "            threshold = df[~np.isnan(df[col])][col].quantile(float(q)/Nlevel)\n",
    "            df[col+'_geq'+str(int(q))+'q'+str(threshold)] = (df[col] >= threshold).astype(float)\n",
    "    df.drop(collist,axis = 1, inplace = True)\n",
    "    \n",
    "class Zindi(StandardDataset):\n",
    "    \"\"\"financial-inclusion-in-africa dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path, label_name='Y', favorable_classes=[1],  \n",
    "                 protected_attribute_names=['sex'],\n",
    "                 privileged_classes=[[1]],\n",
    "                 instance_weights_name=None,\n",
    "                 categorical_features=[],\n",
    "                 features_to_drop=[],\n",
    "                 features_to_keep=[],\n",
    "                 na_values=[], custom_preprocessing=None,\n",
    "                 metadata=None):\n",
    "        \"\"\"See :obj:`RegressionDataset` for a description of the arguments.\"\"\"\n",
    "        \n",
    "\n",
    "        df = pd.read_csv(path)\n",
    "        numericals = [col for col in df.columns if len(df[col].unique())>2 and max(df[col])>1]\n",
    "        code_continuous(df,numericals, 5)\n",
    "\n",
    "        super(Zindi, self).__init__(\n",
    "            df=df, label_name=label_name,\n",
    "            favorable_classes=favorable_classes,\n",
    "            protected_attribute_names=protected_attribute_names,\n",
    "            privileged_classes=privileged_classes,\n",
    "            instance_weights_name=instance_weights_name,\n",
    "            categorical_features=categorical_features,\n",
    "            features_to_keep=features_to_keep,\n",
    "            features_to_drop=features_to_drop, na_values=na_values,\n",
    "            custom_preprocessing=custom_preprocessing, metadata=metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset and specify options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "\n",
    "# Metric used (should be one of allowed_metrics)\n",
    "metric_name = \"Equal opportunity difference\"\n",
    "        \n",
    "#random seed for calibrated equal odds prediction\n",
    "random_seed = 12345679\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# Verify metric name\n",
    "allowed_metrics = [\"Statistical parity difference\",\n",
    "                   \"Average odds difference\",\n",
    "                   \"Equal opportunity difference\"]\n",
    "if metric_name not in allowed_metrics:\n",
    "    raise ValueError(\"Metric name should be one of allowed metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into train, test and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1077127659574468\n",
      "0.1226354941551541\n",
      "Balanced accuracy = 0.6434\n",
      "Statistical parity difference = -0.0545\n",
      "Disparate impact = 0.4572\n",
      "Average odds difference = -0.0502\n",
      "Equal opportunity difference = -0.0747\n",
      "Theil index = 0.1148\n",
      "Balanced accuracy = 0.6550\n",
      "Statistical parity difference = -0.0402\n",
      "Disparate impact = 0.5222\n",
      "Average odds difference = -0.0739\n",
      "Equal opportunity difference = -0.1551\n",
      "Theil index = 0.1037\n"
     ]
    }
   ],
   "source": [
    "K = 5\n",
    "\n",
    "dataset_orig_train= Zindi(path=\"./Huangrui/zindi/zindi_train{}.csv\".format(K))\n",
    "dataset_orig_test= Zindi(path=\"./Huangrui/zindi/zindi_test{}.csv\".format(K))\n",
    "\n",
    "import pickle\n",
    "from sklearn.linear_model import Lasso\n",
    "# 用部分 data训练 biased model\n",
    "selected_dataset,_ = dataset_orig_train.split([0.04], shuffle=True)\n",
    "_ =  dataset_orig_test\n",
    "# Logistic regression classifier and predictions\n",
    "X_train = selected_dataset.features\n",
    "y_train = selected_dataset.labels.ravel()\n",
    "X_test = _.features\n",
    "y_test = _.labels.ravel()\n",
    "lmod = Lasso(alpha = 0.001)\n",
    "lmod.fit(X_train, y_train)\n",
    "y_train_pred = lmod.predict(X_train)>0.5\n",
    "y_test_pred = lmod.predict(X_test)>0.5\n",
    "dataset_orig_train_pred = selected_dataset.copy(deepcopy=True)\n",
    "dataset_orig_train_pred.labels = y_train_pred\n",
    "dataset_orig_test_pred = _.copy(deepcopy=True)\n",
    "dataset_orig_test_pred.labels = y_test_pred\n",
    "print(np.mean(y_train_pred!=y_train))\n",
    "print(np.mean(y_test_pred!=y_test))\n",
    "metric_test = compute_metrics(_, dataset_orig_test_pred, \n",
    "                unprivileged_groups, privileged_groups)\n",
    "metric_train = compute_metrics(selected_dataset, dataset_orig_train_pred,unprivileged_groups, privileged_groups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "bmodels = {}\n",
    "bmodels['clf'] = lmod\n",
    "pickle.dump(bmodels, open(\"experiments/zindi\"+str(K)+'_sex_bmodel.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Training Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18819, 47)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Favorable and unfavorable labels"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Protected attribute names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sex']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Privileged and unprivileged protected attribute values"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.])] [array([0.])]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Dataset feature names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cellphone_access', 'sex', 'country=Kenya', 'country=Rwanda', 'country=Tanzania', 'country=Uganda', 'location_type=Rural', 'location_type=Urban', 'relationship_with_head=Child', 'relationship_with_head=Head of Household', 'relationship_with_head=Other non-relatives', 'relationship_with_head=Other relative', 'relationship_with_head=Parent', 'relationship_with_head=Spouse', 'marital_status=Divorced/Seperated', 'marital_status=Dont know', 'marital_status=Married/Living together', 'marital_status=Single/Never Married', 'marital_status=Widowed', 'education_level=No formal education', 'education_level=Other/Dont know/RTA', 'education_level=Primary education', 'education_level=Secondary education', 'education_level=Tertiary education', 'education_level=Vocational/Specialised training', 'job_type=Dont Know/Refuse to answer', 'job_type=Farming and Fishing', 'job_type=Formally employed Government', 'job_type=Formally employed Private', 'job_type=Government Dependent', 'job_type=Informally employed', 'job_type=No Income', 'job_type=Other Income', 'job_type=Remittance Dependent', 'job_type=Self employed', 'year_geq1q2016.0', 'year_geq2q2017.0', 'year_geq3q2017.0', 'year_geq4q2018.0', 'household_size_geq1q2.0', 'household_size_geq2q3.0', 'household_size_geq3q4.0', 'household_size_geq4q6.0', 'age_geq1q24.0', 'age_geq2q31.0', 'age_geq3q40.0', 'age_geq4q53.0']\n"
     ]
    }
   ],
   "source": [
    "# print out some labels, names, etc.\n",
    "display(Markdown(\"#### Training Dataset shape\"))\n",
    "print(dataset_orig_train.features.shape)\n",
    "display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
    "print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
    "display(Markdown(\"#### Protected attribute names\"))\n",
    "print(dataset_orig_train.protected_attribute_names)\n",
    "display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
    "print(dataset_orig_train.privileged_protected_attributes, \n",
    "      dataset_orig_train.unprivileged_protected_attributes)\n",
    "display(Markdown(\"#### Dataset feature names\"))\n",
    "print(dataset_orig_train.feature_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
