{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook demonstrates the use of the EOP post-processing algorithm for bias mitigation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Load all necessary packages\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from warnings import warn\n",
    "\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.datasets import StandardDataset\n",
    "from aif360.metrics import ClassificationMetric, BinaryLabelDatasetMetric\n",
    "from eq_odds_postprocessing import EqOddsPostprocessing\n",
    "from common_utils import compute_metrics\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interactive, FloatSlider\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.linear_model import Lasso\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huangrui's Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GermanDataset(StandardDataset):\n",
    "    \"\"\"German credit Dataset.\n",
    "\n",
    "    See :file:`aif360/data/raw/german/README.md`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path, label_name='Y', favorable_classes=[1],\n",
    "                 protected_attribute_names=['sex', 'age'],\n",
    "                 privileged_classes=[[1],[1]],\n",
    "                 instance_weights_name=None,\n",
    "                 categorical_features=[],\n",
    "                 features_to_keep=[], features_to_drop=[],\n",
    "                 na_values=[], custom_preprocessing=None,\n",
    "                 metadata=None):\n",
    "        \n",
    "        df = pd.read_csv(path)\n",
    "        \n",
    "\n",
    "        super(GermanDataset, self).__init__(df=df, label_name=label_name,\n",
    "            favorable_classes=favorable_classes,\n",
    "            protected_attribute_names=protected_attribute_names,\n",
    "            privileged_classes=privileged_classes,\n",
    "            instance_weights_name=instance_weights_name,\n",
    "            categorical_features=categorical_features,\n",
    "            features_to_keep=features_to_keep,\n",
    "            features_to_drop=features_to_drop, na_values=na_values,\n",
    "            custom_preprocessing=custom_preprocessing, metadata=metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset and specify options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import dataset\n",
    "dataset_used = \"german\" # \"german\", \"german\", \"compas\"\n",
    "protected_attribute_used = 2 # 1, 2\n",
    "\n",
    "\n",
    "#     dataset_orig = GermanDataset()\n",
    "if protected_attribute_used == 1:\n",
    "    privileged_groups = [{'sex': 1}]\n",
    "    unprivileged_groups = [{'sex': 0}]\n",
    "else:\n",
    "    privileged_groups = [{'age': 1}]\n",
    "    unprivileged_groups = [{'age': 0}]\n",
    "        \n",
    "# Metric used (should be one of allowed_metrics)\n",
    "metric_name = \"Equal opportunity difference\"\n",
    "\n",
    "# Upper and lower bound on the fairness metric used\n",
    "metric_ub = 0.05\n",
    "metric_lb = -0.05\n",
    "        \n",
    "        \n",
    "#random seed for calibrated equal odds prediction\n",
    "random_seed = 12345679\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# Verify metric name\n",
    "allowed_metrics = [\"Statistical parity difference\",\n",
    "                   \"Average odds difference\",\n",
    "                   \"Equal opportunity difference\"]\n",
    "if metric_name not in allowed_metrics:\n",
    "    raise ValueError(\"Metric name should be one of allowed metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into train, test and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted the EOP model\n",
      "Balanced accuracy = 0.9370\n",
      "Statistical parity difference = 0.0915\n",
      "Disparate impact = 1.1389\n",
      "Average odds difference = 0.1446\n",
      "Equal opportunity difference = 0.1074\n",
      "Theil index = 0.0712\n",
      "K = 1, budget = 1\n",
      "The Error for the test dataset is 0.075\n",
      "The Equal opportunity difference for the test dataset is 0.1074\n",
      "Fitted the EOP model\n",
      "Balanced accuracy = 0.9485\n",
      "Statistical parity difference = -0.0383\n",
      "Disparate impact = 0.9379\n",
      "Average odds difference = 0.0614\n",
      "Equal opportunity difference = 0.1228\n",
      "Theil index = 0.0726\n",
      "K = 2, budget = 1\n",
      "The Error for the test dataset is 0.07\n",
      "The Equal opportunity difference for the test dataset is 0.1228\n",
      "Fitted the EOP model\n",
      "Balanced accuracy = 0.8973\n",
      "Statistical parity difference = 0.0794\n",
      "Disparate impact = 1.1221\n",
      "Average odds difference = 0.2189\n",
      "Equal opportunity difference = 0.1520\n",
      "Theil index = 0.1079\n",
      "K = 3, budget = 1\n",
      "The Error for the test dataset is 0.115\n",
      "The Equal opportunity difference for the test dataset is 0.152\n",
      "Fitted the EOP model\n",
      "Balanced accuracy = 0.9366\n",
      "Statistical parity difference = -0.1075\n",
      "Disparate impact = 0.8336\n",
      "Average odds difference = 0.1056\n",
      "Equal opportunity difference = 0.1111\n",
      "Theil index = 0.0712\n",
      "K = 4, budget = 1\n",
      "The Error for the test dataset is 0.075\n",
      "The Equal opportunity difference for the test dataset is 0.1111\n",
      "Fitted the EOP model\n",
      "Balanced accuracy = 0.9177\n",
      "Statistical parity difference = -0.0188\n",
      "Disparate impact = 0.9684\n",
      "Average odds difference = 0.1323\n",
      "Equal opportunity difference = 0.1593\n",
      "Theil index = 0.0985\n",
      "K = 5, budget = 1\n",
      "The Error for the test dataset is 0.1\n",
      "The Equal opportunity difference for the test dataset is 0.1593\n"
     ]
    }
   ],
   "source": [
    "experiments_info = {}\n",
    "budget = 1\n",
    "for K in range(1, 6):\n",
    "    if protected_attribute_used == 1:\n",
    "        dataset_orig_train= GermanDataset(path=\"./Huangrui/german/german_train{}.csv\".format(K),protected_attribute_names=['sex'],\n",
    "                    privileged_classes=[[1]])\n",
    "        dataset_orig_test= GermanDataset(path=\"./Huangrui/german/german_test{}.csv\".format(K),protected_attribute_names=['sex'],\n",
    "                    privileged_classes=[[1]])\n",
    "    else:\n",
    "        dataset_orig_train= GermanDataset(path=\"./Huangrui/german/german_train{}.csv\".format(K),protected_attribute_names=['age'],\n",
    "                    privileged_classes=[[1]])\n",
    "        dataset_orig_test= GermanDataset(path=\"./Huangrui/german/german_test{}.csv\".format(K),protected_attribute_names=['age'],\n",
    "                    privileged_classes=[[1]])\n",
    "    #only use the budget% of the training data\n",
    "    dataset_orig_train,_ = dataset_orig_train.split([budget], shuffle=False)\n",
    "    # Lasso linear classifier and predictions\n",
    "    scale_orig = StandardScaler()\n",
    "    X_train = scale_orig.fit_transform(dataset_orig_train.features)\n",
    "    y_train = dataset_orig_train.labels.ravel()\n",
    "    if protected_attribute_used == 1:\n",
    "        lmod = pickle.load(open('experiments/german'+str(K)+'_sex_bmodel.pkl','rb'))[\"clf\"]\n",
    "    else:\n",
    "        lmod = pickle.load(open('experiments/german'+str(K)+'_age_bmodel.pkl','rb'))[\"clf\"]\n",
    "    y_train_pred = lmod.predict(X_train)\n",
    "\n",
    "    dataset_orig_train_pred = dataset_orig_train.copy(deepcopy=True)\n",
    "    dataset_orig_train_pred.labels = y_train_pred>0.5\n",
    "    sigmoid = lambda x: 1 / (1 + np.exp(0.5-x))\n",
    "    dataset_orig_train_pred.scores = sigmoid(y_train_pred).reshape(-1,1)\n",
    "    #get the biased predictions for test\n",
    "    dataset_orig_test_pred = dataset_orig_test.copy(deepcopy=True)\n",
    "    X_test = scale_orig.transform(dataset_orig_test_pred.features)\n",
    "    y_test = dataset_orig_test_pred.labels\n",
    "    dataset_orig_test_pred.scores = sigmoid(lmod.predict(X_test)).reshape(-1,1)\n",
    "    #load EOP Model\n",
    "    EOP = EqOddsPostprocessing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, seed=random_seed)\n",
    "    #fit EOP model\n",
    "    EOP = EOP.fit(dataset_orig_train, dataset_orig_train_pred)\n",
    "    print(\"Fitted the EOP model\")\n",
    "    # get the EOP predictions for test (Transform the test set)\n",
    "    dataset_transf_test_pred = EOP.predict(dataset_orig_test_pred)\n",
    "\n",
    "    metric_test_aft = compute_metrics(dataset_orig_test, dataset_transf_test_pred, \n",
    "                    unprivileged_groups, privileged_groups)\n",
    "\n",
    "    #自己计算error, 不是balanced accuracy！！！\n",
    "    print(\"K = {}, budget = {}\".format(K, budget))\n",
    "    print(\"The Error for the test dataset is {:.4}\".format(np.mean(dataset_orig_test.labels!=dataset_transf_test_pred.labels)))\n",
    "    print(\"The Equal opportunity difference for the test dataset is {:.4}\".format(metric_test_aft[\"Equal opportunity difference\"]))\n",
    "    experiments_info[\"K = {}, budget = {}\".format(K, budget)] = {\"Error\": np.mean(dataset_orig_test.labels!=dataset_transf_test_pred.labels), \"Equal opportunity difference\": metric_test_aft[\"Equal opportunity difference\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'K = 1, budget = 1': {'Error': 0.075,\n",
       "  'Equal opportunity difference': 0.1074380165289256},\n",
       " 'K = 2, budget = 1': {'Error': 0.07,\n",
       "  'Equal opportunity difference': 0.1228070175438597},\n",
       " 'K = 3, budget = 1': {'Error': 0.115,\n",
       "  'Equal opportunity difference': 0.15200000000000002},\n",
       " 'K = 4, budget = 1': {'Error': 0.075,\n",
       "  'Equal opportunity difference': 0.11111111111111116},\n",
       " 'K = 5, budget = 1': {'Error': 0.1,\n",
       "  'Equal opportunity difference': 0.15929203539823011}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments_info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
