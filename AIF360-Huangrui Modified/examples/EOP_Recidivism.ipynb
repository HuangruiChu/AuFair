{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook demonstrates the use of the EOP post-processing algorithm for bias mitigation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Load all necessary packages\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from warnings import warn\n",
    "\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.datasets import StandardDataset\n",
    "from aif360.metrics import ClassificationMetric, BinaryLabelDatasetMetric\n",
    "from eq_odds_postprocessing import EqOddsPostprocessing\n",
    "from common_utils import compute_metrics\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interactive, FloatSlider\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.linear_model import Lasso\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huangrui's Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_mappings = {\n",
    "    #Huangrui flip the lable\n",
    "    'label_maps': [{0: 'Did recid.', 1: 'No recid.'}],\n",
    "    'protected_attribute_maps': [{0.0: 'Male', 1.0: 'Female'},\n",
    "                                 {1.0: 'Caucasian', 0.0: 'Not Caucasian'}]\n",
    "}\n",
    "def code_continuous(df,collist,Nlevel):\n",
    "    for col in collist:\n",
    "        for q in range(1,Nlevel,1):\n",
    "            threshold = df[~np.isnan(df[col])][col].quantile(float(q)/Nlevel)\n",
    "            df[col+'_geq'+str(int(q))+'q'+str(threshold)] = (df[col] >= threshold).astype(float)\n",
    "    df.drop(collist,axis = 1, inplace = True)\n",
    "class CompasDataset(StandardDataset):\n",
    "    \"\"\"ProPublica COMPAS Dataset.\n",
    "\n",
    "    See :file:`aif360/data/raw/compas/README.md`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, label_name='Y', favorable_classes=[1],\n",
    "                 protected_attribute_names=['sex'],\n",
    "                 privileged_classes=[[1]],\n",
    "                 instance_weights_name=None,\n",
    "                 categorical_features=[],\n",
    "                 features_to_keep=[],\n",
    "                 features_to_drop=[], na_values=[],\n",
    "                 custom_preprocessing=None,\n",
    "                 metadata=default_mappings,\n",
    "                 path='./Huangrui/recidivism/recidivism_test1.csv'):\n",
    "\n",
    "    \n",
    "        df = pd.read_csv(path,index_col=False)\n",
    "        df.rename(columns={'Probationerssex_Female': 'sex'}, inplace=True)\n",
    "        df.drop([\"Probationerssex_Male\",\"Probationerssex_Notascertained\"], axis=1, inplace=True)\n",
    "        numericals = [col for col in df.columns if len(df[col].unique())>2 and max(df[col])>1]\n",
    "        code_continuous(df,numericals, 5)\n",
    "        #flip the Y lable to 0: recid, 1: no recid\n",
    "        df[\"Y\"] = [1 if x == 0 else 0 for x in df[\"Y\"]]\n",
    "        \n",
    "        super(CompasDataset, self).__init__(df=df, label_name=label_name,\n",
    "            favorable_classes=favorable_classes,\n",
    "            protected_attribute_names=protected_attribute_names,\n",
    "            privileged_classes=privileged_classes,\n",
    "            instance_weights_name=instance_weights_name,\n",
    "            categorical_features=categorical_features,\n",
    "            features_to_keep=features_to_keep,\n",
    "            features_to_drop=features_to_drop, na_values=na_values,\n",
    "            custom_preprocessing=custom_preprocessing, metadata=metadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset and specify options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import dataset\n",
    "dataset_used = \"compas\" \n",
    "\n",
    "privileged_groups = [{'sex': 1}] #Females\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "        \n",
    "# Metric used (should be one of allowed_metrics)\n",
    "metric_name = \"Equal opportunity difference\"\n",
    "\n",
    "# Upper and lower bound on the fairness metric used\n",
    "metric_ub = 0.05\n",
    "metric_lb = -0.05\n",
    "        \n",
    "#random seed for calibrated equal odds prediction\n",
    "random_seed = 12345679\n",
    "\n",
    "# Verify metric name\n",
    "allowed_metrics = [\"Statistical parity difference\",\n",
    "                   \"Average odds difference\",\n",
    "                   \"Equal opportunity difference\"]\n",
    "if metric_name not in allowed_metrics:\n",
    "    raise ValueError(\"Metric name should be one of allowed metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into train, test and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\edb\\languagepack\\v2\\Python-3.9\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator Lasso from version 0.22.1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted the EOP model\n",
      "Balanced accuracy = 0.6926\n",
      "Statistical parity difference = -0.1409\n",
      "Disparate impact = 0.8370\n",
      "Average odds difference = -0.1182\n",
      "Equal opportunity difference = -0.0358\n",
      "Theil index = 0.1175\n",
      "Balanced accuracy = 0.6905\n",
      "Statistical parity difference = -0.1091\n",
      "Disparate impact = 0.8689\n",
      "Average odds difference = -0.0894\n",
      "Equal opportunity difference = -0.0010\n",
      "Theil index = 0.1217\n",
      "K = 1, budget = 0.1\n",
      "The Error for the test dataset is 0.2652\n",
      "The Equal opportunity difference for the test dataset is -0.001045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\edb\\languagepack\\v2\\Python-3.9\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator Lasso from version 0.22.1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted the EOP model\n",
      "Balanced accuracy = 0.7199\n",
      "Statistical parity difference = -0.1491\n",
      "Disparate impact = 0.8181\n",
      "Average odds difference = -0.0899\n",
      "Equal opportunity difference = -0.0833\n",
      "Theil index = 0.1328\n",
      "Balanced accuracy = 0.6284\n",
      "Statistical parity difference = -0.0485\n",
      "Disparate impact = 0.9408\n",
      "Average odds difference = 0.0290\n",
      "Equal opportunity difference = -0.0661\n",
      "Theil index = 0.1326\n",
      "K = 2, budget = 0.1\n",
      "The Error for the test dataset is 0.3156\n",
      "The Equal opportunity difference for the test dataset is -0.06607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\edb\\languagepack\\v2\\Python-3.9\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator Lasso from version 0.22.1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted the EOP model\n",
      "Balanced accuracy = 0.6792\n",
      "Statistical parity difference = -0.1491\n",
      "Disparate impact = 0.7700\n",
      "Average odds difference = -0.1183\n",
      "Equal opportunity difference = -0.0689\n",
      "Theil index = 0.2766\n",
      "Balanced accuracy = 0.6084\n",
      "Statistical parity difference = 0.0248\n",
      "Disparate impact = 1.0382\n",
      "Average odds difference = 0.0691\n",
      "Equal opportunity difference = 0.0458\n",
      "Theil index = 0.2170\n",
      "K = 3, budget = 0.1\n",
      "The Error for the test dataset is 0.359\n",
      "The Equal opportunity difference for the test dataset is 0.04577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\edb\\languagepack\\v2\\Python-3.9\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator Lasso from version 0.22.1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted the EOP model\n",
      "Balanced accuracy = 0.7068\n",
      "Statistical parity difference = -0.1407\n",
      "Disparate impact = 0.8254\n",
      "Average odds difference = -0.1110\n",
      "Equal opportunity difference = -0.0463\n",
      "Theil index = 0.1468\n",
      "Balanced accuracy = 0.6281\n",
      "Statistical parity difference = -0.0216\n",
      "Disparate impact = 0.9732\n",
      "Average odds difference = 0.0238\n",
      "Equal opportunity difference = 0.0039\n",
      "Theil index = 0.1272\n",
      "K = 4, budget = 0.1\n",
      "The Error for the test dataset is 0.3139\n",
      "The Equal opportunity difference for the test dataset is 0.003912\n",
      "Fitted the EOP model\n",
      "Balanced accuracy = 0.7136\n",
      "Statistical parity difference = -0.1378\n",
      "Disparate impact = 0.8360\n",
      "Average odds difference = -0.1183\n",
      "Equal opportunity difference = -0.0640\n",
      "Theil index = 0.1206\n",
      "Balanced accuracy = 0.6055\n",
      "Statistical parity difference = -0.0207\n",
      "Disparate impact = 0.9754\n",
      "Average odds difference = 0.0229\n",
      "Equal opportunity difference = -0.0420\n",
      "Theil index = 0.1174\n",
      "K = 5, budget = 0.1\n",
      "The Error for the test dataset is 0.3273\n",
      "The Equal opportunity difference for the test dataset is -0.04196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\edb\\languagepack\\v2\\Python-3.9\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator Lasso from version 0.22.1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "experiments_info = {}\n",
    "bef_experiments_info = {}\n",
    "budget = 0.1\n",
    "for K in range(1, 6):\n",
    "    dataset_orig_train= CompasDataset(path=\"./Huangrui/recidivism/recidivism_train{}.csv\".format(K),protected_attribute_names=['sex'],\n",
    "                privileged_classes=[[1]])\n",
    "    dataset_orig_test= CompasDataset(path=\"./Huangrui/recidivism/recidivism_test{}.csv\".format(K),protected_attribute_names=['sex'],\n",
    "                privileged_classes=[[1]])\n",
    "    #only use the budget% of the training data\n",
    "    dataset_orig_train,_ = dataset_orig_train.split([budget], shuffle=False)\n",
    "    # Lasso linear classifier and predictions\n",
    "    X_train = dataset_orig_train.features\n",
    "    y_train = dataset_orig_train.labels.ravel()\n",
    "    lmod = pickle.load(open('experiments/recidivism'+str(K)+'_sex_bmodel.pkl','rb'))[\"clf\"]\n",
    "   \n",
    "    y_train_pred = lmod.predict(X_train)\n",
    "\n",
    "    dataset_orig_train_pred = dataset_orig_train.copy(deepcopy=True)\n",
    "    #also flip the labels for the train set\n",
    "    dataset_orig_train_pred.labels = (y_train_pred<0.5).reshape(-1,1)\n",
    "    sigmoid = lambda x: 1 / (1 + np.exp(2-4*x))\n",
    "    #also flip the score for the train set\n",
    "    dataset_orig_train_pred.scores = 1- sigmoid(y_train_pred).reshape(-1,1)\n",
    "\n",
    "\n",
    "    dataset_orig_test_pred = dataset_orig_test.copy(deepcopy=True)\n",
    "    X_test = dataset_orig_test.features\n",
    "    y_test = dataset_orig_test.labels\n",
    "    y_test_pred = lmod.predict(X_test)\n",
    "    #also flip the score for the test set\n",
    "    dataset_orig_test_pred.scores = 1 -  sigmoid(y_test_pred).reshape(-1,1)\n",
    "    #also flip the labels for the test set\n",
    "    dataset_orig_test_pred.labels = (y_test_pred<0.5).reshape(-1,1)\n",
    "    #load EOP Model\n",
    "    EOP = EqOddsPostprocessing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, seed=random_seed)\n",
    "    #fit EOP model\n",
    "    EOP = EOP.fit(dataset_orig_train, dataset_orig_train_pred)\n",
    "    print(\"Fitted the EOP model\")\n",
    "    # get the EOP predictions for test (Transform the test set)\n",
    "    dataset_transf_test_pred = EOP.predict(dataset_orig_test_pred)\n",
    "    metric_test_bef = compute_metrics(dataset_orig_test, dataset_orig_test_pred, \n",
    "                    unprivileged_groups, privileged_groups)\n",
    "    metric_test_aft = compute_metrics(dataset_orig_test, dataset_transf_test_pred, \n",
    "                    unprivileged_groups, privileged_groups)\n",
    "\n",
    "    print(\"K = {}, budget = {}\".format(K, budget))\n",
    "    print(\"The Error for the test dataset is {:.4}\".format(np.mean(dataset_orig_test.labels!=dataset_transf_test_pred.labels)))\n",
    "    print(\"The Equal opportunity difference for the test dataset is {:.4}\".format(metric_test_aft[\"Equal opportunity difference\"]))\n",
    "    experiments_info[\"K = {}, budget = {}\".format(K, budget)] = {\"Error\": np.mean(dataset_orig_test.labels!=dataset_transf_test_pred.labels), \"Equal opportunity difference\": metric_test_aft[\"Equal opportunity difference\"]}\n",
    "    bef_experiments_info[\"K = {}, budget = {}\".format(K, budget)] = {\"Error\": np.mean(dataset_orig_test.labels!=dataset_orig_test_pred.labels), \"Equal opportunity difference\": metric_test_bef[\"Equal opportunity difference\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'K = 1, budget = 0.1': {'Error': 0.2652360515021459,\n",
       "  'Equal opportunity difference': -0.0010445866610250265},\n",
       " 'K = 2, budget = 0.1': {'Error': 0.31558608844997854,\n",
       "  'Equal opportunity difference': -0.06606947269597863},\n",
       " 'K = 3, budget = 0.1': {'Error': 0.3589523400601116,\n",
       "  'Equal opportunity difference': 0.045772801579223366},\n",
       " 'K = 4, budget = 0.1': {'Error': 0.31386861313868614,\n",
       "  'Equal opportunity difference': 0.003912405586045775},\n",
       " 'K = 5, budget = 0.1': {'Error': 0.327319587628866,\n",
       "  'Equal opportunity difference': -0.04195758564437191}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.01 we need to seperately run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_info = {}\n",
    "bef_experiments_info = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted the EOP model\n",
      "Balanced accuracy = 0.7136\n",
      "Statistical parity difference = -0.1378\n",
      "Disparate impact = 0.8360\n",
      "Average odds difference = -0.1183\n",
      "Equal opportunity difference = -0.0640\n",
      "Theil index = 0.1206\n",
      "Balanced accuracy = 0.6423\n",
      "Statistical parity difference = -0.2045\n",
      "Disparate impact = 0.7566\n",
      "Average odds difference = -0.1684\n",
      "Equal opportunity difference = -0.1961\n",
      "Theil index = 0.2019\n",
      "K = 5, budget = 0.01\n",
      "The Error for the test dataset is 0.3286\n",
      "The Equal opportunity difference for the test dataset is -0.1961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\edb\\languagepack\\v2\\Python-3.9\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator Lasso from version 0.22.1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "budget = 0.01\n",
    "K = 5\n",
    "dataset_orig_train= CompasDataset(path=\"./Huangrui/recidivism/recidivism_train{}.csv\".format(K),protected_attribute_names=['sex'],\n",
    "            privileged_classes=[[1]])\n",
    "dataset_orig_test= CompasDataset(path=\"./Huangrui/recidivism/recidivism_test{}.csv\".format(K),protected_attribute_names=['sex'],\n",
    "            privileged_classes=[[1]])\n",
    "#only use the budget% of the training data\n",
    "dataset_orig_train,_ = dataset_orig_train.split([budget], shuffle=False)\n",
    "# Lasso linear classifier and predictions\n",
    "X_train = dataset_orig_train.features\n",
    "y_train = dataset_orig_train.labels.ravel()\n",
    "lmod = pickle.load(open('experiments/recidivism'+str(K)+'_sex_bmodel.pkl','rb'))[\"clf\"]\n",
    "\n",
    "y_train_pred = lmod.predict(X_train)\n",
    "\n",
    "dataset_orig_train_pred = dataset_orig_train.copy(deepcopy=True)\n",
    "#also flip the labels for the train set\n",
    "dataset_orig_train_pred.labels = (y_train_pred<0.5).reshape(-1,1)\n",
    "sigmoid = lambda x: 1 / (1 + np.exp(2-4*x))\n",
    "dataset_orig_train_pred.scores = 1- sigmoid(y_train_pred).reshape(-1,1)\n",
    "\n",
    "\n",
    "dataset_orig_test_pred = dataset_orig_test.copy(deepcopy=True)\n",
    "X_test = dataset_orig_test.features\n",
    "y_test = dataset_orig_test.labels\n",
    "y_test_pred = lmod.predict(X_test)\n",
    "dataset_orig_test_pred.scores = 1 -  sigmoid(y_test_pred).reshape(-1,1)\n",
    "#also flip the labels for the test set\n",
    "dataset_orig_test_pred.labels = (y_test_pred<0.5).reshape(-1,1)\n",
    "#load EOP Model\n",
    "EOP = EqOddsPostprocessing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, seed=random_seed)\n",
    "#fit EOP model\n",
    "EOP = EOP.fit(dataset_orig_train, dataset_orig_train_pred)\n",
    "print(\"Fitted the EOP model\")\n",
    "# get the EOP predictions for test (Transform the test set)\n",
    "dataset_transf_test_pred = EOP.predict(dataset_orig_test_pred)\n",
    "metric_test_bef = compute_metrics(dataset_orig_test, dataset_orig_test_pred, \n",
    "                unprivileged_groups, privileged_groups)\n",
    "metric_test_aft = compute_metrics(dataset_orig_test, dataset_transf_test_pred, \n",
    "                unprivileged_groups, privileged_groups)\n",
    "\n",
    "#自己计算error, 不是balanced accuracy！！！\n",
    "print(\"K = {}, budget = {}\".format(K, budget))\n",
    "print(\"The Error for the test dataset is {:.4}\".format(np.mean(dataset_orig_test.labels!=dataset_transf_test_pred.labels)))\n",
    "print(\"The Equal opportunity difference for the test dataset is {:.4}\".format(metric_test_aft[\"Equal opportunity difference\"]))\n",
    "experiments_info[\"K = {}, budget = {}\".format(K, budget)] = {\"Error\": np.mean(dataset_orig_test.labels!=dataset_transf_test_pred.labels), \"Equal opportunity difference\": metric_test_aft[\"Equal opportunity difference\"]}\n",
    "bef_experiments_info[\"K = {}, budget = {}\".format(K, budget)] = {\"Error\": np.mean(dataset_orig_test.labels!=dataset_orig_test_pred.labels), \"Equal opportunity difference\": metric_test_bef[\"Equal opportunity difference\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'K = 1, budget = 0.01': {'Error': 0.3094420600858369,\n",
       "  'Equal opportunity difference': 0.0872395144655419},\n",
       " 'K = 2, budget = 0.01': {'Error': 0.31472735079433234,\n",
       "  'Equal opportunity difference': -0.2132295415427945},\n",
       " 'K = 3, budget = 0.01': {'Error': 0.37741519965650494,\n",
       "  'Equal opportunity difference': -0.11676845254618917},\n",
       " 'K = 4, budget = 0.01': {'Error': 0.31730356376127095,\n",
       "  'Equal opportunity difference': -0.1308156278867576},\n",
       " 'K = 5, budget = 0.01': {'Error': 0.3286082474226804,\n",
       "  'Equal opportunity difference': -0.1961174551386623}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments_info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
