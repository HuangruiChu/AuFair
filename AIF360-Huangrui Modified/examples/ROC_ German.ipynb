{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook demonstrates the use of the Reject Option Classification (ROC) post-processing algorithm for bias mitigation.\n",
    "- The debiasing function used is implemented in the `RejectOptionClassification` class.\n",
    "- Divide the dataset into training, validation, and testing partitions.\n",
    "- Train classifier on original training data.\n",
    "- Estimate the optimal classification threshold, that maximizes balanced accuracy without fairness constraints.\n",
    "- Estimate the optimal classification threshold, and the critical region boundary (ROC margin) using a validation set for the desired constraint on fairness. The best parameters are those that maximize the classification threshold while satisfying the fairness constraints.\n",
    "- The constraints can be used on the following fairness measures:\n",
    "    * Statistical parity difference on the predictions of the classifier\n",
    "    * Average odds difference for the classifier\n",
    "    * Equal opportunity difference for the classifier\n",
    "- Determine the prediction scores for testing data. Using the estimated optimal classification threshold, compute accuracy and fairness metrics.\n",
    "- Using the determined optimal classification threshold and the ROC margin, adjust the predictions. Report accuracy and fairness metric on the new predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Load all necessary packages\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from warnings import warn\n",
    "\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.datasets import StandardDataset\n",
    "from aif360.metrics import ClassificationMetric, BinaryLabelDatasetMetric\n",
    "from aif360.algorithms.postprocessing.reject_option_classification\\\n",
    "        import RejectOptionClassification\n",
    "from common_utils import compute_metrics\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interactive, FloatSlider\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huangrui's Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GermanDataset(StandardDataset):\n",
    "    \"\"\"German credit Dataset.\n",
    "\n",
    "    See :file:`aif360/data/raw/german/README.md`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path, label_name='Y', favorable_classes=[1],\n",
    "                 protected_attribute_names=['sex', 'age'],\n",
    "                 privileged_classes=[[1],[1]],\n",
    "                 instance_weights_name=None,\n",
    "                 categorical_features=[],\n",
    "                 features_to_keep=[], features_to_drop=[],\n",
    "                 na_values=[], custom_preprocessing=None,\n",
    "                 metadata=None):\n",
    "        \n",
    "        df = pd.read_csv(path)\n",
    "        \n",
    "\n",
    "        super(GermanDataset, self).__init__(df=df, label_name=label_name,\n",
    "            favorable_classes=favorable_classes,\n",
    "            protected_attribute_names=protected_attribute_names,\n",
    "            privileged_classes=privileged_classes,\n",
    "            instance_weights_name=instance_weights_name,\n",
    "            categorical_features=categorical_features,\n",
    "            features_to_keep=features_to_keep,\n",
    "            features_to_drop=features_to_drop, na_values=na_values,\n",
    "            custom_preprocessing=custom_preprocessing, metadata=metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset and specify options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import dataset\n",
    "dataset_used = \"german\" # \"german\", \"german\", \"compas\"\n",
    "protected_attribute_used = 1 # 1, 2\n",
    "\n",
    "\n",
    "#     dataset_orig = GermanDataset()\n",
    "if protected_attribute_used == 1:\n",
    "    privileged_groups = [{'sex': 1}]\n",
    "    unprivileged_groups = [{'sex': 0}]\n",
    "else:\n",
    "    privileged_groups = [{'age': 1}]\n",
    "    unprivileged_groups = [{'age': 0}]\n",
    "        \n",
    "# Metric used (should be one of allowed_metrics)\n",
    "metric_name = \"Equal opportunity difference\"\n",
    "\n",
    "# Upper and lower bound on the fairness metric used\n",
    "metric_ub = 0.05\n",
    "metric_lb = -0.05\n",
    "        \n",
    "        \n",
    "#random seed for calibrated equal odds prediction\n",
    "random_seed = 12345679\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# Verify metric name\n",
    "allowed_metrics = [\"Statistical parity difference\",\n",
    "                   \"Average odds difference\",\n",
    "                   \"Equal opportunity difference\"]\n",
    "if metric_name not in allowed_metrics:\n",
    "    raise ValueError(\"Metric name should be one of allowed metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into train, test and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 0.7811\n",
      "Statistical parity difference = -0.2094\n",
      "Disparate impact = 0.6231\n",
      "Average odds difference = -0.1167\n",
      "Equal opportunity difference = -0.0667\n",
      "Theil index = 0.2996\n",
      "Balanced accuracy = 0.7643\n",
      "Statistical parity difference = -0.1467\n",
      "Disparate impact = 0.7859\n",
      "Average odds difference = -0.0686\n",
      "Equal opportunity difference = 0.0143\n",
      "Theil index = 0.1904\n",
      "Balanced accuracy = 0.6536\n",
      "Statistical parity difference = -0.1963\n",
      "Disparate impact = 0.6204\n",
      "Average odds difference = -0.1514\n",
      "Equal opportunity difference = -0.2271\n",
      "Theil index = 0.4305\n",
      "Balanced accuracy = 0.6710\n",
      "Statistical parity difference = 0.0293\n",
      "Disparate impact = 1.0478\n",
      "Average odds difference = 0.1120\n",
      "Equal opportunity difference = -0.0491\n",
      "Theil index = 0.2723\n",
      "K = 1, budget = 0.1\n",
      "The Error for the test dataset is 0.31\n",
      "The Equal opportunity difference for the test dataset is -0.04909\n",
      "Balanced accuracy = 0.6465\n",
      "Statistical parity difference = 0.0258\n",
      "Disparate impact = 1.0435\n",
      "Average odds difference = -0.0701\n",
      "Equal opportunity difference = 0.0309\n",
      "Theil index = 0.2951\n",
      "Balanced accuracy = 0.6465\n",
      "Statistical parity difference = 0.0258\n",
      "Disparate impact = 1.0435\n",
      "Average odds difference = -0.0701\n",
      "Equal opportunity difference = 0.0309\n",
      "Theil index = 0.2951\n",
      "Balanced accuracy = 0.6792\n",
      "Statistical parity difference = 0.0573\n",
      "Disparate impact = 1.1129\n",
      "Average odds difference = 0.1079\n",
      "Equal opportunity difference = 0.0865\n",
      "Theil index = 0.3161\n",
      "Balanced accuracy = 0.6972\n",
      "Statistical parity difference = 0.1863\n",
      "Disparate impact = 1.3673\n",
      "Average odds difference = 0.2225\n",
      "Equal opportunity difference = 0.2757\n",
      "Theil index = 0.2710\n",
      "K = 2, budget = 0.1\n",
      "The Error for the test dataset is 0.305\n",
      "The Equal opportunity difference for the test dataset is 0.2757\n",
      "Balanced accuracy = 0.8073\n",
      "Statistical parity difference = -0.3245\n",
      "Disparate impact = 0.4119\n",
      "Average odds difference = -0.2289\n",
      "Equal opportunity difference = -0.3990\n",
      "Theil index = 0.2773\n",
      "Balanced accuracy = 0.7818\n",
      "Statistical parity difference = 0.1301\n",
      "Disparate impact = 1.2358\n",
      "Average odds difference = 0.2354\n",
      "Equal opportunity difference = 0.0296\n",
      "Theil index = 0.2016\n",
      "Balanced accuracy = 0.6843\n",
      "Statistical parity difference = -0.2509\n",
      "Disparate impact = 0.5346\n",
      "Average odds difference = -0.2286\n",
      "Equal opportunity difference = -0.2806\n",
      "Theil index = 0.4172\n",
      "Balanced accuracy = 0.7032\n",
      "Statistical parity difference = 0.1051\n",
      "Disparate impact = 1.1949\n",
      "Average odds difference = 0.0979\n",
      "Equal opportunity difference = 0.1058\n",
      "Theil index = 0.3032\n",
      "K = 3, budget = 0.1\n",
      "The Error for the test dataset is 0.31\n",
      "The Equal opportunity difference for the test dataset is 0.1058\n",
      "Balanced accuracy = 0.7527\n",
      "Statistical parity difference = -0.2665\n",
      "Disparate impact = 0.4457\n",
      "Average odds difference = -0.1587\n",
      "Equal opportunity difference = -0.2404\n",
      "Theil index = 0.3814\n",
      "Balanced accuracy = 0.7836\n",
      "Statistical parity difference = -0.1319\n",
      "Disparate impact = 0.7788\n",
      "Average odds difference = -0.0577\n",
      "Equal opportunity difference = 0.0321\n",
      "Theil index = 0.2283\n",
      "Balanced accuracy = 0.6999\n",
      "Statistical parity difference = -0.1786\n",
      "Disparate impact = 0.6622\n",
      "Average odds difference = -0.1521\n",
      "Equal opportunity difference = -0.1229\n",
      "Theil index = 0.3428\n",
      "Balanced accuracy = 0.6880\n",
      "Statistical parity difference = -0.0452\n",
      "Disparate impact = 0.9280\n",
      "Average odds difference = -0.0436\n",
      "Equal opportunity difference = 0.0666\n",
      "Theil index = 0.2377\n",
      "K = 4, budget = 0.1\n",
      "The Error for the test dataset is 0.295\n",
      "The Equal opportunity difference for the test dataset is 0.06661\n",
      "Balanced accuracy = 0.7692\n",
      "Statistical parity difference = -0.2183\n",
      "Disparate impact = 0.6586\n",
      "Average odds difference = -0.1270\n",
      "Equal opportunity difference = -0.1826\n",
      "Theil index = 0.2441\n",
      "Balanced accuracy = 0.7643\n",
      "Statistical parity difference = -0.0216\n",
      "Disparate impact = 0.9513\n",
      "Average odds difference = 0.0759\n",
      "Equal opportunity difference = 0.0089\n",
      "Theil index = 0.3814\n",
      "Balanced accuracy = 0.7145\n",
      "Statistical parity difference = -0.1575\n",
      "Disparate impact = 0.7396\n",
      "Average odds difference = -0.0981\n",
      "Equal opportunity difference = -0.1517\n",
      "Theil index = 0.2682\n",
      "Balanced accuracy = 0.6966\n",
      "Statistical parity difference = -0.1176\n",
      "Disparate impact = 0.7442\n",
      "Average odds difference = -0.0673\n",
      "Equal opportunity difference = -0.1013\n",
      "Theil index = 0.3874\n",
      "K = 5, budget = 0.1\n",
      "The Error for the test dataset is 0.355\n",
      "The Equal opportunity difference for the test dataset is -0.1013\n"
     ]
    }
   ],
   "source": [
    "experiments_info = {}\n",
    "budget = 0.1\n",
    "for K in range(1, 6):\n",
    "    if protected_attribute_used == 1:\n",
    "        dataset_orig_train= GermanDataset(path=\"./Huangrui/german/german_train{}.csv\".format(K),protected_attribute_names=['sex'],\n",
    "                    privileged_classes=[[1]])\n",
    "        dataset_orig_test= GermanDataset(path=\"./Huangrui/german/german_test{}.csv\".format(K),protected_attribute_names=['sex'],\n",
    "                    privileged_classes=[[1]])\n",
    "    else:\n",
    "        dataset_orig_train= GermanDataset(path=\"./Huangrui/german/german_train{}.csv\".format(K),protected_attribute_names=['age'],\n",
    "                    privileged_classes=[[1]])\n",
    "        dataset_orig_test= GermanDataset(path=\"./Huangrui/german/german_test{}.csv\".format(K),protected_attribute_names=['age'],\n",
    "                    privileged_classes=[[1]])\n",
    "    #only use the budget% of the training data\n",
    "    dataset_orig_train,_ = dataset_orig_train.split([budget], shuffle=False)\n",
    "\n",
    "    # Lasso linear classifier and predictions\n",
    "    scale_orig = StandardScaler()\n",
    "    X_train = scale_orig.fit_transform(dataset_orig_train.features)\n",
    "    y_train = dataset_orig_train.labels.ravel()\n",
    "    if protected_attribute_used == 1:\n",
    "        lmod = pickle.load(open('experiments/german'+str(K)+'_sex_bmodel.pkl','rb'))[\"clf\"]\n",
    "    else:\n",
    "        lmod = pickle.load(open('experiments/german'+str(K)+'_age_bmodel.pkl','rb'))[\"clf\"]\n",
    "    y_train_pred = lmod.predict(X_train)\n",
    "\n",
    "    dataset_orig_train_pred = dataset_orig_train.copy(deepcopy=True)\n",
    "    dataset_orig_train_pred.labels = y_train_pred.reshape(-1,1)\n",
    "    sigmoid = lambda x: 1 / (1 + np.exp(0.5-x))\n",
    "    dataset_orig_train_pred.scores = sigmoid(y_train_pred).reshape(-1,1)\n",
    "\n",
    "    dataset_orig_test_pred = dataset_orig_test.copy(deepcopy=True)\n",
    "    X_test = scale_orig.transform(dataset_orig_test_pred.features)\n",
    "    y_test = dataset_orig_test_pred.labels\n",
    "    dataset_orig_test_pred.scores = sigmoid(lmod.predict(X_test)).reshape(-1,1)\n",
    "\n",
    "    #### Best threshold for classification only (no fairness)\n",
    "    num_thresh = 100\n",
    "    ba_arr = np.zeros(num_thresh)\n",
    "    class_thresh_arr = np.linspace(0.01, 0.99, num_thresh)\n",
    "    for idx, class_thresh in enumerate(class_thresh_arr):\n",
    "        \n",
    "        fav_inds = dataset_orig_train_pred.scores > class_thresh\n",
    "        dataset_orig_train_pred.labels[fav_inds] = dataset_orig_train_pred.favorable_label\n",
    "        dataset_orig_train_pred.labels[~fav_inds] = dataset_orig_train_pred.unfavorable_label\n",
    "        \n",
    "        classified_metric_orig_train = ClassificationMetric(dataset_orig_train,\n",
    "                                                dataset_orig_train_pred, \n",
    "                                                unprivileged_groups=unprivileged_groups,\n",
    "                                                privileged_groups=privileged_groups)\n",
    "        \n",
    "        ba_arr[idx] = 0.5*(classified_metric_orig_train.true_positive_rate()\\\n",
    "                        +classified_metric_orig_train.true_negative_rate())\n",
    "\n",
    "    best_ind = np.where(ba_arr == np.max(ba_arr))[0][0]\n",
    "    best_class_thresh = class_thresh_arr[best_ind]\n",
    "\n",
    "    # print(\"Best balanced accuracy (no fairness constraints) = %.4f\" % np.max(ba_arr))\n",
    "    # print(\"Optimal classification threshold (no fairness constraints) = %.4f\" % best_class_thresh)\n",
    "    #### Estimate optimal parameters for the ROC method\n",
    "    ROC = RejectOptionClassification(unprivileged_groups=unprivileged_groups, \n",
    "                                    privileged_groups=privileged_groups, \n",
    "                                    low_class_thresh=0.01, high_class_thresh=0.99,\n",
    "                                    num_class_thresh=100, num_ROC_margin=50,\n",
    "                                    metric_name=metric_name,\n",
    "                                    metric_ub=metric_ub, metric_lb=metric_lb)\n",
    "    ROC = ROC.fit(dataset_orig_train, dataset_orig_train_pred)\n",
    "    # print(\"Optimal classification threshold (with fairness constraints) = %.4f\" % ROC.classification_threshold)\n",
    "    # print(\"Optimal ROC margin = %.4f\" % ROC.ROC_margin)\n",
    "\n",
    "    # Metrics for the train set\n",
    "    fav_inds = dataset_orig_train_pred.scores > best_class_thresh\n",
    "    dataset_orig_train_pred.labels[fav_inds] = dataset_orig_train_pred.favorable_label\n",
    "    dataset_orig_train_pred.labels[~fav_inds] = dataset_orig_train_pred.unfavorable_label\n",
    "\n",
    "    # display(Markdown(\"#### train set\"))\n",
    "    # display(Markdown(\"##### Raw predictions - No fairness constraints, only maximizing balanced accuracy\"))\n",
    "\n",
    "    metric_train_bef = compute_metrics(dataset_orig_train, dataset_orig_train_pred, \n",
    "                    unprivileged_groups, privileged_groups)\n",
    "\n",
    "    # Transform the validation set\n",
    "    dataset_transf_train_pred = ROC.predict(dataset_orig_train_pred)\n",
    "\n",
    "    # display(Markdown(\"#### train set\"))\n",
    "    # display(Markdown(\"##### Transformed predictions - With fairness constraints\"))\n",
    "    metric_train_aft = compute_metrics(dataset_orig_train, dataset_transf_train_pred, \n",
    "                    unprivileged_groups, privileged_groups)\n",
    "    # Testing: Check if the metric optimized has not become worse\n",
    "    assert np.abs(metric_train_aft[metric_name]) <= np.abs(metric_train_bef[metric_name])\n",
    "\n",
    "    # Metrics for the test set\n",
    "    fav_inds = dataset_orig_test_pred.scores > best_class_thresh\n",
    "    dataset_orig_test_pred.labels[fav_inds] = dataset_orig_test_pred.favorable_label\n",
    "    dataset_orig_test_pred.labels[~fav_inds] = dataset_orig_test_pred.unfavorable_label\n",
    "\n",
    "    # display(Markdown(\"#### Test set\"))\n",
    "    # display(Markdown(\"##### Raw predictions - No fairness constraints, only maximizing balanced accuracy\"))\n",
    "\n",
    "    metric_test_bef = compute_metrics(dataset_orig_test, dataset_orig_test_pred, \n",
    "                    unprivileged_groups, privileged_groups)\n",
    "    # Metrics for the transformed test set\n",
    "    dataset_transf_test_pred = ROC.predict(dataset_orig_test_pred)\n",
    "\n",
    "    # display(Markdown(\"#### Test set\"))\n",
    "    # display(Markdown(\"##### Transformed predictions - With fairness constraints\"))\n",
    "    metric_test_aft = compute_metrics(dataset_orig_test, dataset_transf_test_pred, \n",
    "                    unprivileged_groups, privileged_groups)\n",
    "\n",
    "    #自己计算error, 不是balanced accuracy！！！\n",
    "    print(\"K = {}, budget = {}\".format(K, budget))\n",
    "    print(\"The Error for the test dataset is {:.4}\".format(np.mean(dataset_orig_test.labels!=dataset_transf_test_pred.labels)))\n",
    "    print(\"The Equal opportunity difference for the test dataset is {:.4}\".format(metric_test_aft[\"Equal opportunity difference\"]))\n",
    "    experiments_info[\"K = {}, budget = {}\".format(K, budget)] = {\"Error\": np.mean(dataset_orig_test.labels!=dataset_transf_test_pred.labels), \"Equal opportunity difference\": metric_test_aft[\"Equal opportunity difference\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'K = 1, budget = 0.1': {'Error': 0.31,\n",
       "  'Equal opportunity difference': -0.04909496652615919},\n",
       " 'K = 2, budget = 0.1': {'Error': 0.305,\n",
       "  'Equal opportunity difference': 0.27573027573027575},\n",
       " 'K = 3, budget = 0.1': {'Error': 0.31,\n",
       "  'Equal opportunity difference': 0.10576923076923073},\n",
       " 'K = 4, budget = 0.1': {'Error': 0.295,\n",
       "  'Equal opportunity difference': 0.06661206661206664},\n",
       " 'K = 5, budget = 0.1': {'Error': 0.355,\n",
       "  'Equal opportunity difference': -0.10128458498023718}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments_info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
