{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.linear_model import LinearRegression, Ridge, LogisticRegression\n",
    "from sklearn import tree\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_T = 500\n",
    "alpha = 1e-4 # Hyper-  \n",
    "gamma = 1 # Hyper-\n",
    "#set random seed to make results reproducible\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_info = {}\n",
    "experiment_info[\"K\"] = []\n",
    "experiment_info[\"budget\"] = []\n",
    "experiment_info[\"Error\"] = []\n",
    "experiment_info[\"Equal opportunity difference\"] = []\n",
    "experiment_info[\"alpha\"] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../predict-responsibly/data/\"\n",
    "dataset = \"adult\"\n",
    "protected_feature = \"sex\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1, budget=1, error=0.17113814364272623, eod=0.19556495506950689\n",
      "error0=0.20780825302693354, error1=0.09518935516888434\n",
      "K=2, budget=1, error=0.16383333333333333, eod=0.14347374839032984\n",
      "error0=0.20438683948155534, error1=0.08199195171026157\n",
      "K=3, budget=1, error=0.15783333333333333, eod=0.11039119421452698\n",
      "error0=0.19664328657314628, error1=0.08067729083665338\n",
      "K=4, budget=1, error=0.16483333333333333, eod=0.12080262081707077\n",
      "error0=0.20609542842867848, error1=0.08212318477716575\n",
      "K=5, budget=1, error=0.15769294882480414, eod=0.11281036754094398\n",
      "error0=0.19621513944223107, error1=0.07967725668179526\n"
     ]
    }
   ],
   "source": [
    "errors_pre_0 = []\n",
    "errors_pre_1 = []\n",
    "errors_post_0 = []\n",
    "errors_post_1 = []\n",
    "\n",
    "for K in [1,2,3,4,5]:\n",
    "    db = np.load(os.path.join(path,dataset,\"{}{}_{}.npz\".format(dataset,K,protected_feature)))\n",
    "    x_val = db[\"x_train\"]\n",
    "    y_val = db[\"y_train\"]\n",
    "    x_test = db[\"x_test\"]\n",
    "    y_test = db[\"y_test\"]\n",
    "    valid_index = np.arange(len(x_val))\n",
    "    for budget in [1,0.1]:\n",
    "        for alpha in [1e-4,1e-3,1e-2,1e-1]:\n",
    "            logits = np.log(db[\"ydm_train\"]/(1-db[\"ydm_train\"]))\n",
    "            test_logits = np.log(db[\"ydm_test\"]/(1-db[\"ydm_test\"]))\n",
    "            best_epoch, best_acc = -1,0\n",
    "            best_logits_valid = logits\n",
    "            predicted_test_logits = test_logits\n",
    "            #use budget % of the validation set for training\n",
    "            valid_index =random.sample(list(valid_index), int(len(valid_index) * budget))\n",
    "\n",
    "\n",
    "            # get the idxs1 and idxs2\n",
    "            idxs1 = random.sample(list(valid_index), int(len(valid_index) * 0.7))\n",
    "            idxs2 = list(set(valid_index) - set(idxs1))\n",
    "            for t in range(max_T):\n",
    "                # probs_heldout = sess_run(tf.nn.sigmoid(logits), x_val[idxs2], latent_val[idxs2], sess)\n",
    "                # logits updates every iteration, thus the probs_heldout is different\n",
    "                probs_heldout = sigmoid(logits)[idxs2]\n",
    "                #heldout_loss = np.mean(-y_val[idxs2] * np.log(probs_heldout + 1e-20) - (1-y_val[idxs2]) * np.log(1-probs_heldout + 1e-20))\n",
    "                heldout_acc =  np.mean((probs_heldout>0.5)==y_val[idxs2])\n",
    "                # probs = sess_run(tf.nn.sigmoid(logits), x_val, latent_val ,sess)\n",
    "                # 应为logits是更新的，所以probs也是更新的\n",
    "                probs = sigmoid(logits)\n",
    "                val_loss = np.mean(-y_val * np.log(probs + 1e-20) - (1 - y_val) * np.log(1 - probs + 1e-20))\n",
    "                val_acc = np.mean((probs > 0.5) == y_val)\n",
    "                # losses.append(val_loss)\n",
    "                if heldout_acc > best_acc:\n",
    "                    # print(\"Update!\")\n",
    "                    best_epoch = t\n",
    "                    best_acc = heldout_acc\n",
    "                    best_logits_valid = logits\n",
    "                    predicted_test_logits = test_logits\n",
    "                # delta = res(probs,y_val)\n",
    "                residual = probs - y_val\n",
    "                for i in range(3):\n",
    "                    # define the control\n",
    "                    control_idx1 = db[\"ydm_train\"][idxs1]>0.5\n",
    "                    control_idx2 = db[\"ydm_train\"][idxs2]>0.5\n",
    "                    if i==0: \n",
    "                        # X_1, f1(x) > 1/2\n",
    "                        temp_s = control_idx1\n",
    "                        temp_s_heldout = control_idx2\n",
    "                    elif i ==1:\n",
    "                        # X_0, f0(x) ≤ 1/2\n",
    "                        temp_s = 1- control_idx1\n",
    "                        temp_s_heldout = 1- control_idx2\n",
    "                    else:\n",
    "                        # X\n",
    "                        temp_s = np.ones_like(control_idx1)\n",
    "                        temp_s_heldout = np.ones_like(control_idx2)\n",
    "                    # get the fresh sample for training\n",
    "                    samples1 = np.where(temp_s == 1)[0]\n",
    "                    samples2 = np.where(temp_s_heldout == 1)[0]\n",
    "                    # train the regression model \n",
    "                    clf = Ridge(alpha=1) # 如果我不变呢\n",
    "                    # clf = DecisionTreeRegressor(max_depth = 5)\n",
    "                    # 如果要把protected feature 去掉 可以考率生成一个新的x_train、valid\n",
    "                    # 我没有去拟合他的 res 那个function，我直接拟合已知的residual （f(x) - y）\n",
    "                    clf.fit(x_val[idxs1][samples1],residual[idxs1][samples1])\n",
    "                    clf_prediction = clf.predict(x_val[idxs2][samples2])\n",
    "                    corr = np.mean(clf_prediction * residual[idxs2][samples2])\n",
    "                    # print(t, i, corr)\n",
    "                    if corr > alpha:\n",
    "                        # h_models.append(clf)\n",
    "                        # h = (tf.matmul(latent_ph, tf.constant(np.expand_dims(clf.coef_,-1),\n",
    "                        #                                         dtype=tf.float32))[:,0] + clf.intercept_)\n",
    "                        #here, we update h\n",
    "                        h = clf.predict(x_val)\n",
    "                        h_test = clf.predict(x_test)\n",
    "                        # print(h.shape)\n",
    "                        # print(h)\n",
    "                        # when update the logits we only update the logits of current set\n",
    "                        # logits -= .1 * h * s\n",
    "                        control = db[\"ydm_train\"]>0.5\n",
    "                        #here ydm_test is the f_0(x_test) \n",
    "                        control_test = db[\"ydm_test\"]>0.5\n",
    "                        if i == 0:\n",
    "                            # update logits of X_1\n",
    "                            s = control\n",
    "                            s_test = control_test\n",
    "                        elif i == 1:\n",
    "                            # update logits of X_0\n",
    "                            s = 1 - control\n",
    "                            s_test = 1 - control_test\n",
    "                        else:\n",
    "                            # update all logits (This might never used)\n",
    "                            s = np.ones_like(control)\n",
    "                            s_test = np.ones_like(control_test)\n",
    "                        logits -= gamma * h * s\n",
    "                        # update the test logits accordingly\n",
    "                        test_logits -= gamma * h_test * s_test\n",
    "                        break\n",
    "                # 如果 i == 2 说明没有在X_0,X_1找到合适的h，那么就不更新了\n",
    "                if i==2:\n",
    "                    break\n",
    "            #Huangrui add\n",
    "            EPS = 1e-8\n",
    "            Y_hat = sigmoid(predicted_test_logits)>0.5\n",
    "            A = db[\"attr_test\"]\n",
    "            Y = db[\"y_test\"]\n",
    "            # print(\"A\",A.shape)\n",
    "            # print(\"Y\",Y.shape)\n",
    "            TP = np.multiply(Y, Y_hat)\n",
    "            mask0 = np.multiply(Y,1-A)\n",
    "            mask1 = np.multiply(Y,A)\n",
    "            TP0 = np.multiply(TP, mask0)\n",
    "            TP1 = np.multiply(TP, mask1)\n",
    "            tpr0 = np.sum(TP0) / (np.sum(mask0) + EPS)\n",
    "            tpr1 = np.sum(TP1) / (np.sum(mask1) + EPS)\n",
    "            #get the error rate of the test set\n",
    "            error = np.mean(Y_hat != Y)\n",
    "            eod = np.abs(tpr0 - tpr1)\n",
    "            print(\"K={}, budget={}, error={}, eod={}\".format(K,budget,error,eod))\n",
    "            experiment_info[\"K\"].append(K)\n",
    "            experiment_info[\"budget\"].append(budget)\n",
    "            experiment_info[\"Error\"].append(error)\n",
    "            experiment_info[\"Equal opportunity difference\"].append(eod)\n",
    "            experiment_info[\"alpha\"].append(alpha)\n",
    "            Ydm = db[\"ydm_test\"]>0.5\n",
    "            Y_hat0 = Ydm[A==0]\n",
    "            Y_hat1 = Ydm[A==1]\n",
    "            Y0 = Y[A==0]\n",
    "            Y1 = Y[A==1]\n",
    "            error0 = np.mean(Y_hat0 != Y0)\n",
    "            error1 = np.mean(Y_hat1 != Y1)\n",
    "            errors_pre_0.append(error0)\n",
    "            errors_pre_1.append(error1)\n",
    "            Y_hat_post0 = Y_hat[A==0]\n",
    "            Y_hat_post1 = Y_hat[A==1]\n",
    "            error_post0 = np.mean(Y_hat_post0 != Y0)\n",
    "            error_post1 = np.mean(Y_hat_post1 != Y1)\n",
    "            print(\"error0={}, error1={}\".format(error_post0,error_post1))\n",
    "            errors_post_0.append(error_post0)\n",
    "            errors_post_1.append(error_post1)``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For sex = 0, pre error = 0.20911582724854688, post error = 0.20222978939050895, the difference is -0.00688603785803793\n",
      "For sex = 1, pre error = 0.08443877843241596, post error = 0.08393180783495205, the difference is -0.0005069705974639072\n"
     ]
    }
   ],
   "source": [
    "#print the pre and pros error for each group\n",
    "print(\"For sex = 0, pre error = {}, post error = {}, the difference is {}\".format(np.mean(errors_pre_0),np.mean(errors_post_0), np.mean(errors_post_0)-np.mean(errors_pre_0)))\n",
    "print(\"For sex = 1, pre error = {}, post error = {}, the difference is {}\".format(np.mean(errors_pre_1),np.mean(errors_post_1), np.mean(errors_post_1)-np.mean(errors_pre_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.20780825302693354,\n",
       " 0.20438683948155534,\n",
       " 0.19664328657314628,\n",
       " 0.20609542842867848,\n",
       " 0.19621513944223107]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_post_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict(experiment_info)\n",
    "#save df to csv\n",
    "df.to_csv(\"results/adult_sex.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# let us check based on multiacc metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now get the error and eod of human\n",
    "eods = []\n",
    "errors_pre_0 = []\n",
    "errors_pre_1 = []\n",
    "errors_post_0 = []\n",
    "errors_post_1 = []\n",
    "\n",
    "for K in [1,2,3,4,5]:\n",
    "    db = np.load(os.path.join(path,dataset,\"{}{}_{}.npz\".format(dataset,K,protected_feature)))\n",
    "    Y_hat = db[\"ydm_test\"]>0.5\n",
    "    A = db[\"attr_test\"]\n",
    "    Y = db[\"y_test\"]\n",
    "    Y_hat0 = Y_hat[A==0]\n",
    "    Y_hat1 = Y_hat[A==1]\n",
    "    Y0 = Y[A==0]\n",
    "    Y1 = Y[A==1]\n",
    "    error0 = np.mean(Y_hat0 != Y0)\n",
    "    error1 = np.mean(Y_hat1 != Y1)\n",
    "    errors_pre_0.append(error0)\n",
    "    errors_pre_1.append(error1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
