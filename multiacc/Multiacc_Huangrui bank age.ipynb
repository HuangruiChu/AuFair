{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.linear_model import LinearRegression, Ridge, LogisticRegression\n",
    "from sklearn import tree\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_T = 500\n",
    "thresh = 1e-4 # Hyper-\n",
    "#set random seed to make results reproducible\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_info = {}\n",
    "experiment_info[\"K\"] = []\n",
    "experiment_info[\"budget\"] = []\n",
    "experiment_info[\"Error\"] = []\n",
    "experiment_info[\"Equal opportunity difference\"] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../predict-responsibly/data/\"\n",
    "dataset = \"bank\"\n",
    "protected_feature = \"age\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1, budget=1, error=0.10611776283418074, eod=0.16682422276994296\n",
      "error0=0.1989247311827957, error1=0.10319742852309254\n",
      "K=1, budget=0.1, error=0.1113662456946039, eod=0.1614024355303959\n",
      "error0=0.1989247311827957, error1=0.10861106411774657\n",
      "K=2, budget=1, error=0.09904886848146933, eod=0.11347599754499432\n",
      "error0=0.1592356687898089, error1=0.09745834034674297\n",
      "K=2, budget=0.1, error=0.10036077402427025, eod=0.10379795629591393\n",
      "error0=0.16560509554140126, error1=0.09863659316613364\n",
      "K=3, budget=1, error=0.1031485733027222, eod=0.23203870611303878\n",
      "error0=0.13297872340425532, error1=0.10219966159052453\n",
      "K=3, budget=0.1, error=0.10511643161692358, eod=0.25642895000952903\n",
      "error0=0.14361702127659576, error1=0.1038917089678511\n",
      "K=4, budget=1, error=0.10905214824532633, eod=0.06295707481171353\n",
      "error0=0.21875, error1=0.10609632873021219\n",
      "K=4, budget=0.1, error=0.10806821908822564, eod=0.0813990459717795\n",
      "error0=0.2, error1=0.10559110811721119\n",
      "K=5, budget=1, error=0.098245038543546, eod=0.16879407602558993\n",
      "error0=0.15606936416184972, error1=0.09655638082376772\n",
      "K=5, budget=0.1, error=0.10168935542069871, eod=0.21533850479785305\n",
      "error0=0.15606936416184972, error1=0.100101282916948\n"
     ]
    }
   ],
   "source": [
    "errors_pre_0 = []\n",
    "errors_pre_1 = []\n",
    "errors_post_0 = []\n",
    "errors_post_1 = []\n",
    "for K in [1,2,3,4,5]:\n",
    "    db = np.load(os.path.join(path,dataset,\"{}{}_{}.npz\".format(dataset,K,protected_feature)))\n",
    "    x_val = db[\"x_train\"]\n",
    "    y_val = db[\"y_train\"]\n",
    "    x_test = db[\"x_test\"]\n",
    "    y_test = db[\"y_test\"]\n",
    "    logits = np.log(db[\"ydm_train\"]/(1-db[\"ydm_train\"]))\n",
    "    test_logits = np.log(db[\"ydm_test\"]/(1-db[\"ydm_test\"]))\n",
    "    # print(\"x_val\",x_val.shape)\n",
    "    # print(\"y_val\",y_val.shape)\n",
    "    # print(\"x_test\",x_test.shape)\n",
    "    # print(\"y_test\",y_test.shape)\n",
    "    # print(\"logits\",logits.shape)\n",
    "    # print(\"test_logits\",test_logits.shape)\n",
    "    # get the validation index\n",
    "\n",
    "    valid_index = np.arange(len(x_val))\n",
    "    for budget in [1,0.1]:\n",
    "        best_epoch, best_acc = -1,0\n",
    "        best_logits_valid = logits\n",
    "        predicted_test_logits = test_logits\n",
    "        #use budget % of the validation set for training\n",
    "        valid_index =random.sample(list(valid_index), int(len(valid_index) * budget))\n",
    "\n",
    "\n",
    "        # get the idxs1 and idxs2\n",
    "        idxs1 = random.sample(list(valid_index), int(len(valid_index) * 0.7))\n",
    "        idxs2 = list(set(valid_index) - set(idxs1))\n",
    "\n",
    "        # save the coefficients\n",
    "        # h_models = []\n",
    "        # losses = []\n",
    "        for t in range(max_T):\n",
    "            # probs_heldout = sess_run(tf.nn.sigmoid(logits), x_val[idxs2], latent_val[idxs2], sess)\n",
    "            # logits updates every iteration, thus the probs_heldout is different\n",
    "            probs_heldout = sigmoid(logits)[idxs2]\n",
    "            #heldout_loss = np.mean(-y_val[idxs2] * np.log(probs_heldout + 1e-20) - (1-y_val[idxs2]) * np.log(1-probs_heldout + 1e-20))\n",
    "            heldout_acc =  np.mean((probs_heldout>0.5)==y_val[idxs2])\n",
    "            # probs = sess_run(tf.nn.sigmoid(logits), x_val, latent_val ,sess)\n",
    "            # 应为logits是更新的，所以probs也是更新的\n",
    "            probs = sigmoid(logits)\n",
    "            val_loss = np.mean(-y_val * np.log(probs + 1e-20) - (1 - y_val) * np.log(1 - probs + 1e-20))\n",
    "            val_acc = np.mean((probs > 0.5) == y_val)\n",
    "            # losses.append(val_loss)\n",
    "            if heldout_acc > best_acc:\n",
    "                # print(\"Update!\")\n",
    "                best_epoch = t\n",
    "                best_acc = heldout_acc\n",
    "                best_logits_valid = logits\n",
    "                predicted_test_logits = test_logits\n",
    "            # delta = res(probs,y_val)\n",
    "            residual = probs - y_val\n",
    "            for i in range(3):\n",
    "                # define the control\n",
    "                control_idx1 = db[\"ydm_train\"][idxs1]>0.5\n",
    "                control_idx2 = db[\"ydm_train\"][idxs2]>0.5\n",
    "                if i==0: \n",
    "                    # X_1, f1(x) > 1/2\n",
    "                    temp_s = control_idx1\n",
    "                    temp_s_heldout = control_idx2\n",
    "                elif i ==1:\n",
    "                    # X_0, f0(x) ≤ 1/2\n",
    "                    temp_s = 1- control_idx1\n",
    "                    temp_s_heldout = 1- control_idx2\n",
    "                else:\n",
    "                    # X\n",
    "                    temp_s = np.ones_like(control_idx1)\n",
    "                    temp_s_heldout = np.ones_like(control_idx2)\n",
    "                # get the fresh sample for training\n",
    "                samples1 = np.where(temp_s == 1)[0]\n",
    "                samples2 = np.where(temp_s_heldout == 1)[0]\n",
    "                # train the regression model \n",
    "                clf = Ridge(alpha=1) # 如果我不变呢\n",
    "                # clf = DecisionTreeRegressor(max_depth = 5)\n",
    "                # 如果要把protected feature 去掉 可以考率生成一个新的x_train、valid\n",
    "                # 我没有去拟合他的 res 那个function，我直接拟合已知的residual （f(x) - y）\n",
    "                clf.fit(x_val[idxs1][samples1],residual[idxs1][samples1])\n",
    "                clf_prediction = clf.predict(x_val[idxs2][samples2])\n",
    "                corr = np.mean(clf_prediction * residual[idxs2][samples2])\n",
    "                # print(t, i, corr)\n",
    "                if corr > thresh:\n",
    "                    # h_models.append(clf)\n",
    "                    # h = (tf.matmul(latent_ph, tf.constant(np.expand_dims(clf.coef_,-1),\n",
    "                    #                                         dtype=tf.float32))[:,0] + clf.intercept_)\n",
    "                    #here, we update h\n",
    "                    h = clf.predict(x_val)\n",
    "                    h_test = clf.predict(x_test)\n",
    "                    # print(h.shape)\n",
    "                    # print(h)\n",
    "                    # when update the logits we only update the logits of current set\n",
    "                    # logits -= .1 * h * s\n",
    "                    control = db[\"ydm_train\"]>0.5\n",
    "                    #here ydm_test is the f_0(x_test) \n",
    "                    control_test = db[\"ydm_test\"]>0.5\n",
    "                    if i == 0:\n",
    "                        # update logits of X_1\n",
    "                        s = control\n",
    "                        s_test = control_test\n",
    "                    elif i == 1:\n",
    "                        # update logits of X_0\n",
    "                        s = 1 - control\n",
    "                        s_test = 1 - control_test\n",
    "                    else:\n",
    "                        # update all logits (This might never used)\n",
    "                        s = np.ones_like(control)\n",
    "                        s_test = np.ones_like(control_test)\n",
    "                    logits -= .1 * h * s\n",
    "                    # update the test logits accordingly\n",
    "                    test_logits -= .1 * h_test * s_test\n",
    "                    break\n",
    "            # 如果 i == 2 说明没有在X_0,X_1找到合适的h，那么就不更新了\n",
    "            if i==2:\n",
    "                break\n",
    "        #Huangrui add\n",
    "        EPS = 1e-8\n",
    "        Y_hat = sigmoid(predicted_test_logits)>0.5\n",
    "        A = db[\"attr_test\"]\n",
    "        Y = db[\"y_test\"]\n",
    "        # print(\"A\",A.shape)\n",
    "        # print(\"Y\",Y.shape)\n",
    "        TP = np.multiply(Y, Y_hat)\n",
    "        mask0 = np.multiply(Y,1-A)\n",
    "        mask1 = np.multiply(Y,A)\n",
    "        TP0 = np.multiply(TP, mask0)\n",
    "        TP1 = np.multiply(TP, mask1)\n",
    "        tpr0 = np.sum(TP0) / (np.sum(mask0) + EPS)\n",
    "        tpr1 = np.sum(TP1) / (np.sum(mask1) + EPS)\n",
    "        #get the error rate of the test set\n",
    "        error = np.mean(Y_hat != Y)\n",
    "        eod = np.abs(tpr0 - tpr1)\n",
    "        print(\"K={}, budget={}, error={}, eod={}\".format(K,budget,error,eod))\n",
    "        experiment_info[\"K\"].append(K)\n",
    "        experiment_info[\"budget\"].append(budget)\n",
    "        experiment_info[\"Error\"].append(error)\n",
    "        experiment_info[\"Equal opportunity difference\"].append(eod)\n",
    "        Ydm = db[\"ydm_test\"]>0.5\n",
    "        Y_hat0 = Ydm[A==0]\n",
    "        Y_hat1 = Ydm[A==1]\n",
    "        Y0 = Y[A==0]\n",
    "        Y1 = Y[A==1]\n",
    "        error0 = np.mean(Y_hat0 != Y0)\n",
    "        error1 = np.mean(Y_hat1 != Y1)\n",
    "        errors_pre_0.append(error0)\n",
    "        errors_pre_1.append(error1)\n",
    "        Y_hat_post0 = Y_hat[A==0]\n",
    "        Y_hat_post1 = Y_hat[A==1]\n",
    "        error_post0 = np.mean(Y_hat_post0 != Y0)\n",
    "        error_post1 = np.mean(Y_hat_post1 != Y1)\n",
    "        print(\"error0={}, error1={}\".format(error_post0,error_post1))\n",
    "        errors_post_0.append(error_post0)\n",
    "        errors_post_1.append(error_post1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For age = 0, pre error = 0.17983995593195937, post error = 0.17301746997013523, the difference is -0.006822485961824137\n",
      "For age = 1, pre error = 0.10751916658197799, post error = 0.10223398973002304, the difference is -0.005285176851954954\n"
     ]
    }
   ],
   "source": [
    "#print the pre and pros error for each group\n",
    "print(\"For age = 0, pre error = {}, post error = {}, the difference is {}\".format(np.mean(errors_pre_0),np.mean(errors_post_0), np.mean(errors_post_0)-np.mean(errors_pre_0)))\n",
    "print(\"For age = 1, pre error = {}, post error = {}, the difference is {}\".format(np.mean(errors_pre_1),np.mean(errors_post_1), np.mean(errors_post_1)-np.mean(errors_pre_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df = pd.DataFrame.from_dict(experiment_info)\n",
    "# #save df to csv\n",
    "# df.to_csv(\"results/bank_age.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1, error=0.11595866819747416, eod=0.10165155973124806\n",
      "K=2, error=0.10511643161692358, eod=0.23134759960997658\n",
      "K=3, error=0.10774024270252541, eod=0.2281614526834963\n",
      "K=4, error=0.10888816005247622, eod=0.24292527806755798\n",
      "K=5, error=0.11005412497949811, eod=0.24330042300979127\n"
     ]
    }
   ],
   "source": [
    "# Now get the error and eod of human\n",
    "eods = []\n",
    "errors = []\n",
    "for K in [1,2,3,4,5]:\n",
    "    db = np.load(os.path.join(path,dataset,\"{}{}_{}.npz\".format(dataset,K,protected_feature)))\n",
    "    Y_hat = db[\"ydm_test\"]>0.5\n",
    "    A = db[\"attr_test\"]\n",
    "    Y = db[\"y_test\"]\n",
    "    # print(\"A\",A.shape)\n",
    "    # print(\"Y\",Y.shape)\n",
    "    TP = np.multiply(Y, Y_hat)\n",
    "    mask0 = np.multiply(Y,1-A)\n",
    "    mask1 = np.multiply(Y,A)\n",
    "    TP0 = np.multiply(TP, mask0)\n",
    "    TP1 = np.multiply(TP, mask1)\n",
    "    tpr0 = np.sum(TP0) / (np.sum(mask0) + EPS)\n",
    "    tpr1 = np.sum(TP1) / (np.sum(mask1) + EPS)\n",
    "    #get the error rate of the test set\n",
    "    error = np.mean(Y_hat != Y)\n",
    "    eod = np.abs(tpr0 - tpr1)\n",
    "    errors.append(error)\n",
    "    eods.append(eod)\n",
    "    print(\"K={}, error={}, eod={}\".format(K,error,eod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1095515255097795"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20947726262041405"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(eods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
