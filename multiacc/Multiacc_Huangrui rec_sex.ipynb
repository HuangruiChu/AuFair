{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.linear_model import LinearRegression, Ridge, LogisticRegression\n",
    "from sklearn import tree\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_T = 500\n",
    "thresh = 1e-4 # Hyper-\n",
    "#set random seed to make results reproducible\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_info = {}\n",
    "experiment_info[\"K\"] = []\n",
    "experiment_info[\"budget\"] = []\n",
    "experiment_info[\"Error\"] = []\n",
    "experiment_info[\"Equal opportunity difference\"] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../predict-responsibly/data/\"\n",
    "dataset = \"recidivism\"\n",
    "protected_feature = \"sex\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1, budget=1, error=0.2793991416309013, eod=0.03109298140733674\n",
      "K=1, budget=0.1, error=0.3034334763948498, eod=0.06621224940278447\n",
      "K=2, budget=1, error=0.2657793044224989, eod=0.08655400821251147\n",
      "K=2, budget=0.1, error=0.26449119793902964, eod=0.08448729982063041\n",
      "K=3, budget=1, error=0.38686131386861317, eod=0.03543999257516206\n",
      "K=3, budget=0.1, error=0.3911550021468441, eod=0.023341352804922555\n",
      "K=4, budget=1, error=0.29841133533705455, eod=0.002836494075710738\n",
      "K=4, budget=0.1, error=0.3027050236152855, eod=0.006618486141736435\n",
      "K=5, budget=1, error=0.23711340206185566, eod=0.08426590534354961\n",
      "K=5, budget=0.1, error=0.23324742268041238, eod=0.07039967369602806\n"
     ]
    }
   ],
   "source": [
    "for K in [1,2,3,4,5]:\n",
    "    db = np.load(os.path.join(path,\"compas\",\"{}{}_{}.npz\".format(dataset,K,protected_feature)))\n",
    "    x_val = db[\"x_train\"]\n",
    "    y_val = db[\"y_train\"]\n",
    "    x_test = db[\"x_test\"]\n",
    "    y_test = db[\"y_test\"]\n",
    "    logits = np.log(db[\"ydm_train\"]/(1-db[\"ydm_train\"]))\n",
    "    test_logits = np.log(db[\"ydm_test\"]/(1-db[\"ydm_test\"]))\n",
    "    # print(\"x_val\",x_val.shape)\n",
    "    # print(\"y_val\",y_val.shape)\n",
    "    # print(\"x_test\",x_test.shape)\n",
    "    # print(\"y_test\",y_test.shape)\n",
    "    # print(\"logits\",logits.shape)\n",
    "    # print(\"test_logits\",test_logits.shape)\n",
    "    # get the validation index\n",
    "\n",
    "    valid_index = np.arange(len(x_val))\n",
    "    for budget in [1,0.1]:\n",
    "        best_epoch, best_acc = -1,0\n",
    "        best_logits_valid = logits\n",
    "        predicted_test_logits = test_logits\n",
    "        #use budget % of the validation set for training\n",
    "        valid_index =random.sample(list(valid_index), int(len(valid_index) * budget))\n",
    "\n",
    "\n",
    "        # get the idxs1 and idxs2\n",
    "        idxs1 = random.sample(list(valid_index), int(len(valid_index) * 0.7))\n",
    "        idxs2 = list(set(valid_index) - set(idxs1))\n",
    "\n",
    "        # save the coefficients\n",
    "        # h_models = []\n",
    "        # losses = []\n",
    "        for t in range(max_T):\n",
    "            # probs_heldout = sess_run(tf.nn.sigmoid(logits), x_val[idxs2], latent_val[idxs2], sess)\n",
    "            # logits updates every iteration, thus the probs_heldout is different\n",
    "            probs_heldout = sigmoid(logits)[idxs2]\n",
    "            #heldout_loss = np.mean(-y_val[idxs2] * np.log(probs_heldout + 1e-20) - (1-y_val[idxs2]) * np.log(1-probs_heldout + 1e-20))\n",
    "            heldout_acc =  np.mean((probs_heldout>0.5)==y_val[idxs2])\n",
    "            # probs = sess_run(tf.nn.sigmoid(logits), x_val, latent_val ,sess)\n",
    "            # 应为logits是更新的，所以probs也是更新的\n",
    "            probs = sigmoid(logits)\n",
    "            val_loss = np.mean(-y_val * np.log(probs + 1e-20) - (1 - y_val) * np.log(1 - probs + 1e-20))\n",
    "            val_acc = np.mean((probs > 0.5) == y_val)\n",
    "            # losses.append(val_loss)\n",
    "            if heldout_acc > best_acc:\n",
    "                # print(\"Update!\")\n",
    "                best_epoch = t\n",
    "                best_acc = heldout_acc\n",
    "                best_logits_valid = logits\n",
    "                predicted_test_logits = test_logits\n",
    "            # delta = res(probs,y_val)\n",
    "            residual = probs - y_val\n",
    "            for i in range(3):\n",
    "                # define the control\n",
    "                control_idx1 = db[\"ydm_train\"][idxs1]>0.5\n",
    "                control_idx2 = db[\"ydm_train\"][idxs2]>0.5\n",
    "                if i==0: \n",
    "                    # X_1, f1(x) > 1/2\n",
    "                    temp_s = control_idx1\n",
    "                    temp_s_heldout = control_idx2\n",
    "                elif i ==1:\n",
    "                    # X_0, f0(x) ≤ 1/2\n",
    "                    temp_s = 1- control_idx1\n",
    "                    temp_s_heldout = 1- control_idx2\n",
    "                else:\n",
    "                    # X\n",
    "                    temp_s = np.ones_like(control_idx1)\n",
    "                    temp_s_heldout = np.ones_like(control_idx2)\n",
    "                # get the fresh sample for training\n",
    "                samples1 = np.where(temp_s == 1)[0]\n",
    "                samples2 = np.where(temp_s_heldout == 1)[0]\n",
    "                # train the regression model \n",
    "                clf = Ridge(alpha=1) # 如果我不变呢\n",
    "                # clf = DecisionTreeRegressor(max_depth = 5)\n",
    "                # 如果要把protected feature 去掉 可以考率生成一个新的x_train、valid\n",
    "                # 我没有去拟合他的 res 那个function，我直接拟合已知的residual （f(x) - y）\n",
    "                clf.fit(x_val[idxs1][samples1],residual[idxs1][samples1])\n",
    "                clf_prediction = clf.predict(x_val[idxs2][samples2])\n",
    "                corr = np.mean(clf_prediction * residual[idxs2][samples2])\n",
    "                # print(t, i, corr)\n",
    "                if corr > thresh:\n",
    "                    # h_models.append(clf)\n",
    "                    # h = (tf.matmul(latent_ph, tf.constant(np.expand_dims(clf.coef_,-1),\n",
    "                    #                                         dtype=tf.float32))[:,0] + clf.intercept_)\n",
    "                    #here, we update h\n",
    "                    h = clf.predict(x_val)\n",
    "                    h_test = clf.predict(x_test)\n",
    "                    # print(h.shape)\n",
    "                    # print(h)\n",
    "                    # when update the logits we only update the logits of current set\n",
    "                    # logits -= .1 * h * s\n",
    "                    control = db[\"ydm_train\"]>0.5\n",
    "                    #here ydm_test is the f_0(x_test) \n",
    "                    control_test = db[\"ydm_test\"]>0.5\n",
    "                    if i == 0:\n",
    "                        # update logits of X_1\n",
    "                        s = control\n",
    "                        s_test = control_test\n",
    "                    elif i == 1:\n",
    "                        # update logits of X_0\n",
    "                        s = 1 - control\n",
    "                        s_test = 1 - control_test\n",
    "                    else:\n",
    "                        # update all logits (This might never used)\n",
    "                        s = np.ones_like(control)\n",
    "                        s_test = np.ones_like(control_test)\n",
    "                    logits -= .1 * h * s\n",
    "                    # update the test logits accordingly\n",
    "                    test_logits -= .1 * h_test * s_test\n",
    "                    break\n",
    "            # 如果 i == 2 说明没有在X_0,X_1找到合适的h，那么就不更新了\n",
    "            if i==2:\n",
    "                break\n",
    "        #Huangrui add\n",
    "        EPS = 1e-8\n",
    "        Y_hat = sigmoid(predicted_test_logits)>0.5\n",
    "        A = db[\"attr_test\"]\n",
    "        Y = db[\"y_test\"]\n",
    "        # print(\"A\",A.shape)\n",
    "        # print(\"Y\",Y.shape)\n",
    "        TP = np.multiply(Y, Y_hat)\n",
    "        mask0 = np.multiply(Y,1-A)\n",
    "        mask1 = np.multiply(Y,A)\n",
    "        TP0 = np.multiply(TP, mask0)\n",
    "        TP1 = np.multiply(TP, mask1)\n",
    "        tpr0 = np.sum(TP0) / (np.sum(mask0) + EPS)\n",
    "        tpr1 = np.sum(TP1) / (np.sum(mask1) + EPS)\n",
    "        #get the error rate of the test set\n",
    "        error = np.mean(Y_hat != Y)\n",
    "        eod = np.abs(tpr0 - tpr1)\n",
    "        print(\"K={}, budget={}, error={}, eod={}\".format(K,budget,error,eod))\n",
    "        experiment_info[\"K\"].append(K)\n",
    "        experiment_info[\"budget\"].append(budget)\n",
    "        experiment_info[\"Error\"].append(error)\n",
    "        experiment_info[\"Equal opportunity difference\"].append(eod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict(experiment_info)\n",
    "#save df to csv\n",
    "df.to_csv(\"results/recidivism_sex.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1, error=0.26824034334763946, eod=0.027215449276761228\n",
      "K=2, error=0.24903392013739803, eod=0.07588144784135853\n",
      "K=3, error=0.3276084156290253, eod=0.06727892412711123\n",
      "K=4, error=0.2589094031773293, eod=0.044623159236297116\n",
      "K=5, error=0.23797250859106528, eod=0.06703099506657462\n"
     ]
    }
   ],
   "source": [
    "# Now get the error and eod of human\n",
    "eods = []\n",
    "errors = []\n",
    "for K in [1,2,3,4,5]:\n",
    "    db = np.load(os.path.join(path,\"compas\",\"{}{}_{}.npz\".format(dataset,K,protected_feature)))\n",
    "    Y_hat = db[\"ydm_test\"]>0.5\n",
    "    A = db[\"attr_test\"]\n",
    "    Y = db[\"y_test\"]\n",
    "    # print(\"A\",A.shape)\n",
    "    # print(\"Y\",Y.shape)\n",
    "    TP = np.multiply(Y, Y_hat)\n",
    "    mask0 = np.multiply(Y,1-A)\n",
    "    mask1 = np.multiply(Y,A)\n",
    "    TP0 = np.multiply(TP, mask0)\n",
    "    TP1 = np.multiply(TP, mask1)\n",
    "    tpr0 = np.sum(TP0) / (np.sum(mask0) + EPS)\n",
    "    tpr1 = np.sum(TP1) / (np.sum(mask1) + EPS)\n",
    "    #get the error rate of the test set\n",
    "    error = np.mean(Y_hat != Y)\n",
    "    eod = np.abs(tpr0 - tpr1)\n",
    "    errors.append(error)\n",
    "    eods.append(eod)\n",
    "    print(\"K={}, error={}, eod={}\".format(K,error,eod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2683529181764915"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05640599510962054"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(eods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
